{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "726882b7-bf79-45f9-abb6-87ee98b387d2",
   "metadata": {},
   "source": [
    "# Introduction aux Réseaux de Neurones avec TensorFlow\n",
    "\n",
    "Dans ce notebook, nous allons explorer les concepts de base des réseaux de neurones et apprendre à construire et entraîner un réseau de neurones simple en utilisant TensorFlow. Nous utiliserons le jeu de données MNIST pour entraîner un modèle qui reconnaît les chiffres manuscrits.\n",
    "\n",
    "\n",
    "**Ressources supplémentaires :**\n",
    "\n",
    "- [Documentation officielle de TensorFlow](https://www.tensorflow.org/learn)\n",
    "- [Tutoriels TensorFlow pour débutants](https://www.tensorflow.org/tutorials)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cbd2ee-5c12-4fad-9817-3230ad6ecbd1",
   "metadata": {},
   "source": [
    "# Introduction aux Réseaux de Neurones\n",
    "\n",
    "Les réseaux de neurones artificiels sont des modèles computationnels inspirés du cerveau humain. Ils sont conçus pour reconnaître des motifs complexes et résoudre des problèmes tels que la classification, la régression et la reconnaissance de formes. Ils constituent le fondement de l'apprentissage profond (*deep learning*), une branche de l'intelligence artificielle qui a connu une croissance exponentielle ces dernières années.\n",
    "\n",
    "## Qu'est-ce qu'un Réseau de Neurones ?\n",
    "\n",
    "Un réseau de neurones est composé d'unités de traitement appelées **neurones artificiels**, organisées en **couches**. Chaque neurone reçoit des signaux d'entrée, les traite en appliquant une fonction d'activation, puis transmet le résultat aux neurones de la couche suivante.\n",
    "\n",
    "### Structure d'un Réseau de Neurones\n",
    "\n",
    "- **Couche d'entrée** : Reçoit les données initiales du problème.\n",
    "- **Couches cachées** : Effectuent des transformations intermédiaires des données.\n",
    "- **Couche de sortie** : Produit la solution ou la prédiction finale.\n",
    "\n",
    "![Structure d'un réseau de neurones](https://www.aspexit.com/wp-content/uploads/2019/04/Architecture-perceptron-multi-couches-1.png)\n",
    "\n",
    "*Note : Cette image représente la structure typique d'un réseau de neurones avec une couche d'entrée, des couches cachées et une couche de sortie.*\n",
    "\n",
    "## Fonctionnement d'un Neurone Artificiel\n",
    "\n",
    "Un neurone artificiel réalise les opérations suivantes :\n",
    "\n",
    "1. **Réception des Entrées** : Chaque entrée est multipliée par un poids synaptique.\n",
    "2. **Somme Pondérée** : Les produits sont additionnés pour former une somme pondérée.\n",
    "3. **Ajout du Biais** : Un terme de biais est ajouté pour ajuster le résultat.\n",
    "4. **Activation** : La somme pondérée passe à travers une fonction d'activation pour introduire de la non-linéarité.\n",
    "5. **Sortie** : Le résultat est transmis aux neurones suivants.\n",
    "\n",
    "### Fonctions d'Activation Courantes\n",
    "\n",
    "- **Sigmoïde** : Convient pour les sorties probabilistes.\n",
    "- **Tanh** : Centre les données autour de zéro.\n",
    "- **ReLU (Rectified Linear Unit)** : Accélère la convergence de l'entraînement.\n",
    "\n",
    "## Apprentissage dans les Réseaux de Neurones\n",
    "\n",
    "### Propagation Avant (*Forward Propagation*)\n",
    "\n",
    "Les données traversent le réseau de la couche d'entrée à la couche de sortie. À chaque neurone, les entrées sont transformées et transmises à la couche suivante.\n",
    "\n",
    "### Calcul de la Perte\n",
    "\n",
    "La **fonction de perte** mesure la différence entre la sortie prédite et la sortie réelle. Elle guide l'optimisation du réseau.\n",
    "\n",
    "### Rétropropagation (*Backpropagation*)\n",
    "\n",
    "L'algorithme de rétropropagation calcule les gradients de la fonction de perte par rapport aux poids du réseau. Ces gradients sont utilisés pour mettre à jour les poids en minimisant la perte.\n",
    "\n",
    "### Optimisation\n",
    "\n",
    "Des algorithmes comme **la descente de gradient stochastique (SGD)**, **Adam**, ou **RMSprop** sont utilisés pour ajuster les poids en fonction des gradients.\n",
    "\n",
    "## Types de Réseaux de Neurones\n",
    "\n",
    "### Perceptron Multicouche (*Multilayer Perceptron - MLP*)\n",
    "\n",
    "- **Description** : Réseau de neurones entièrement connecté avec au moins une couche cachée.\n",
    "- **Utilisation** : Problèmes de classification et de régression basiques.\n",
    "\n",
    "### Réseaux de Neurones Convolutifs (*Convolutional Neural Networks - CNN*)\n",
    "\n",
    "- **Description** : Intègrent des couches convolutives pour extraire des caractéristiques spatiales.\n",
    "- **Utilisation** : Traitement d'images et de vidéos.\n",
    "\n",
    "### Réseaux de Neurones Récurrents (*Recurrent Neural Networks - RNN*)\n",
    "\n",
    "- **Description** : Prennent en compte les dépendances séquentielles dans les données.\n",
    "- **Utilisation** : Traitement du langage naturel, séries temporelles.\n",
    "\n",
    "### Réseaux à Mémoire à Long Court Terme (*Long Short-Term Memory - LSTM*)\n",
    "\n",
    "- **Description** : Une variante des RNN qui résout le problème du gradient évanescent.\n",
    "- **Utilisation** : Modélisation de séquences longues.\n",
    "\n",
    "## Applications des Réseaux de Neurones\n",
    "\n",
    "- **Vision par Ordinateur** : Reconnaissance faciale, détection d'objets.\n",
    "- **Traitement du Langage Naturel** : Traduction automatique, analyse de sentiments.\n",
    "- **Reconnaissance Vocale** : Assistants vocaux, transcription automatique.\n",
    "- **Jeux et Simulations** : Intelligence artificielle dans les jeux vidéo.\n",
    "- **Santé** : Diagnostic médical assisté par ordinateur.\n",
    "\n",
    "## Avantages et Limites\n",
    "\n",
    "### Avantages\n",
    "\n",
    "- **Apprentissage de Caractéristiques Complexes** : Capables de modéliser des relations non linéaires.\n",
    "- **Adaptabilité** : Peuvent être appliqués à divers types de données.\n",
    "- **Performance** : Souvent supérieurs aux méthodes traditionnelles dans de nombreux domaines.\n",
    "\n",
    "### Limites\n",
    "\n",
    "- **Besoin en Données** : Nécessitent de grandes quantités de données pour un entraînement efficace.\n",
    "- **Complexité Computationnelle** : Exigent une puissance de calcul élevée.\n",
    "- **Interprétabilité** : Difficiles à interpréter (effet de \"boîte noire\").\n",
    "\n",
    "## Étapes pour Construire un Réseau de Neurones\n",
    "\n",
    "1. **Définir le Problème** : Classification, régression, etc.\n",
    "2. **Collecter et Préparer les Données** : Nettoyage, normalisation, division en ensembles d'entraînement et de test.\n",
    "3. **Choisir une Architecture** : Sélection du type de réseau adapté au problème.\n",
    "4. **Configurer le Modèle** : Définir les couches, les fonctions d'activation, la fonction de perte, et l'optimiseur.\n",
    "5. **Entraîner le Modèle** : Ajuster les poids en utilisant les données d'entraînement.\n",
    "6. **Évaluer le Modèle** : Utiliser les données de test pour mesurer la performance.\n",
    "7. **Ajuster les Hyperparamètres** : Modifier le taux d'apprentissage, le nombre de couches, etc.\n",
    "8. **Déployer le Modèle** : Utiliser le modèle entraîné en production.\n",
    "\n",
    "## Conseils pour les Débutants\n",
    "\n",
    "- **Commencer Simple** : Débutez avec des architectures simples avant de passer à des modèles plus complexes.\n",
    "- **Visualiser les Données** : Comprenez vos données en les explorant visuellement.\n",
    "- **Comprendre les Hyperparamètres** : Expérimentez avec différents paramètres pour voir leur impact.\n",
    "- **Utiliser des Bibliothèques** : Des frameworks comme TensorFlow ou PyTorch facilitent la mise en œuvre.\n",
    "- **Apprendre de la Communauté** : Participez à des forums, lisez des articles, suivez des tutoriels.\n",
    "\n",
    "## Ressources Utiles\n",
    "\n",
    "- **Tutoriels** :\n",
    "  - [Tutoriels TensorFlow](https://www.tensorflow.org/tutorials)\n",
    "  - [Tutoriels PyTorch](https://pytorch.org/tutorials/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4214c7ac-0e65-4b90-8da7-5a9796a1d385",
   "metadata": {},
   "source": [
    "## Chargement et Prétraitement des Données\n",
    "\n",
    "Pour illustrer le fonctionnement des réseaux de neurones, nous utiliserons le jeu de données **MNIST**, qui contient des images de chiffres manuscrits. Le chargement et le prétraitement des données sont des étapes cruciales pour obtenir de bonnes performances. Elles consistent à préparer les données pour qu'elles puissent être utilisées efficacement par le modèle de réseau de neurones.\n",
    "\n",
    "### Étapes du Chargement et Prétraitement\n",
    "\n",
    "1. **Chargement des Données** : Récupération des données d’entraînement et de test.\n",
    "2. **Normalisation** : Mise à l’échelle des valeurs des pixels pour les rendre homogènes.\n",
    "3. **Visualisation des Données** (facultatif) : Examiner les exemples pour mieux comprendre les données.\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Chargement des Données\n",
    "\n",
    "Dans Keras, le jeu de données MNIST peut être directement chargé via l'API `keras.datasets`. Cela retourne deux ensembles de données :\n",
    "- **Ensemble d’entraînement** : Utilisé pour entraîner le modèle.\n",
    "- **Ensemble de test** : Utilisé pour évaluer la performance du modèle.\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Chargement du jeu de données MNIST\n",
    "mnist = keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "print(\"Dimensions des données d'entraînement :\", x_train.shape, y_train.shape)\n",
    "print(\"Dimensions des données de test :\", x_test.shape, y_test.shape)\n",
    "```\n",
    "\n",
    "### 2. Visualisation des Données\n",
    "\n",
    "Il est souvent utile de visualiser quelques exemples de données pour mieux comprendre la tâche que le modèle va apprendre. Chaque image du jeu de données MNIST est une matrice de 28x28 pixels en niveaux de gris (de 0 à 255), représentant un chiffre entre 0 et 9.\n",
    "\n",
    "```python\n",
    "# Affichage de quelques exemples d'images\n",
    "plt.figure(figsize=(10, 1))\n",
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i+1)\n",
    "    plt.imshow(x_train[i], cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.title(y_train[i])\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Normalisation\n",
    "\n",
    "Les réseaux de neurones convergent plus rapidement lorsque les données sont **normalisées**. Dans le cas d’images en niveaux de gris, les pixels ont des valeurs entre 0 et 255. Nous allons diviser chaque pixel par 255 pour que toutes les valeurs soient dans l'intervalle \\([0, 1]\\).\n",
    "\n",
    "```python\n",
    "# Normalisation des valeurs des pixels\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "```\n",
    "\n",
    "Après cette normalisation, chaque pixel a une valeur entre 0 et 1, ce qui permet d'accélérer l'apprentissage et d'améliorer la stabilité du modèle.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Reshaping des Données (Optionnel)\n",
    "\n",
    "Certaines architectures, notamment les réseaux convolutifs (CNN), nécessitent que les données aient une certaine forme (e.g., 28x28x1 pour une image 2D avec un seul canal de couleur). Dans notre exemple simple avec un réseau de neurones entièrement connecté, cette étape n'est pas obligatoire, car nous utiliserons une couche `Flatten` dans le modèle pour convertir l'image en un vecteur.\n",
    "\n",
    "Cependant, si vous utilisez un CNN, vous pouvez procéder ainsi :\n",
    "\n",
    "```python\n",
    "# Ajouter une dimension de canal pour CNN\n",
    "x_train = x_train.reshape(-1, 28, 28, 1)\n",
    "x_test = x_test.reshape(-1, 28, 28, 1)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Récapitulatif du Code\n",
    "\n",
    "Voici le code complet pour le chargement et le prétraitement des données MNIST :\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Chargement du jeu de données\n",
    "mnist = keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Visualisation des premières images\n",
    "plt.figure(figsize=(10, 1))\n",
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i+1)\n",
    "    plt.imshow(x_train[i], cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.title(y_train[i])\n",
    "plt.show()\n",
    "\n",
    "# Normalisation des images\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "Avec ces données normalisées et prêtes, nous pouvons maintenant construire et entraîner notre modèle de réseau de neurones pour reconnaître les chiffres manuscrits !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a22db4e-142b-4bfc-8e6b-02c3a6c664d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A vous de jouer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d59894b-8867-4d7b-88cc-72c02aa6d3cf",
   "metadata": {},
   "source": [
    "## Construction et compilation du Modèle de Réseau de Neurones\n",
    "\n",
    "Pour construire un modèle de réseau de neurones, nous allons utiliser l'API `Sequential` de Keras, qui permet de définir le modèle couche par couche. Dans notre exemple, nous allons créer un modèle simple avec une couche d'entrée, une couche cachée entièrement connectée, et une couche de sortie. \n",
    "\n",
    "### Architecture du Modèle\n",
    "\n",
    "Notre modèle sera composé des couches suivantes :\n",
    "\n",
    "1. **Couche de Flatten** : Cette couche convertit les images de 28x28 pixels en un vecteur 1D de 784 éléments. Cela rend les données compatibles avec les couches denses entièrement connectées.\n",
    "2. **Couche Dense Cachée** : Contient 128 neurones avec une fonction d'activation ReLU. Elle capture les motifs importants de l'image pour la classification.\n",
    "3. **Couche Dense de Sortie** : Cette couche contient 10 neurones avec une fonction d'activation softmax, correspondant aux 10 classes de chiffres (de 0 à 9). La fonction softmax transforme les valeurs en probabilités.\n",
    "\n",
    "### Définition du Modèle\n",
    "\n",
    "Voici comment définir le modèle avec Keras :\n",
    "\n",
    "```python\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "\n",
    "# Construction du modèle\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=(28, 28)),       # Couche d'entrée qui aplatit l'image\n",
    "    Dense(128, activation='relu'),       # Couche cachée avec 128 neurones et activation ReLU\n",
    "    Dense(10, activation='softmax')      # Couche de sortie avec 10 neurones et activation softmax\n",
    "])\n",
    "```\n",
    "\n",
    "### Explications des Couches\n",
    "\n",
    "- **Flatten** : Prend une entrée 2D (28x28 pixels) et la convertit en un vecteur 1D (784 éléments). Cela est nécessaire car la couche dense attend un vecteur en entrée.\n",
    "- **Dense (128, ReLU)** : Couche dense avec 128 neurones. La fonction d'activation **ReLU** (Rectified Linear Unit) permet de modéliser des relations non linéaires et est largement utilisée pour les couches cachées.\n",
    "- **Dense (10, Softmax)** : Couche dense avec 10 neurones pour les 10 classes (de 0 à 9). La fonction **softmax** convertit les sorties en probabilités, facilitant l’interprétation des prédictions du modèle pour chaque classe.\n",
    "\n",
    "### Compilation du Modèle\n",
    "\n",
    "Avant d'entraîner le modèle, il faut le **compiler** en spécifiant :\n",
    "- **Fonction de perte** : La fonction qui mesure l'erreur entre les prédictions et les vraies étiquettes. Nous utilisons ici la `sparse_categorical_crossentropy` pour un problème de classification multi-classes.\n",
    "- **Optimiseur** : La méthode d'optimisation pour ajuster les poids. Nous utilisons **Adam**, un optimiseur adaptatif efficace pour l'apprentissage profond.\n",
    "- **Métriques** : Les mesures de performance, ici `accuracy` pour la précision.\n",
    "\n",
    "```python\n",
    "# Compilation du modèle\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "```\n",
    "\n",
    "### Affichage du Résumé du Modèle\n",
    "\n",
    "Pour avoir un aperçu de l'architecture du modèle, y compris le nombre de paramètres à entraîner, on peut utiliser la méthode `summary()` :\n",
    "\n",
    "```python\n",
    "# Afficher le résumé du modèle\n",
    "model.summary()\n",
    "```\n",
    "\n",
    "La sortie sera similaire à ceci :\n",
    "\n",
    "```\n",
    "Model: \"sequential\"\n",
    "_________________________________________________________________\n",
    " Layer (type)                Output Shape              Param #\n",
    "=================================================================\n",
    " flatten (Flatten)           (None, 784)               0\n",
    " dense (Dense)               (None, 128)               100480\n",
    " dense_1 (Dense)             (None, 10)                1290\n",
    "=================================================================\n",
    "Total params: 101,770\n",
    "Trainable params: 101,770\n",
    "Non-trainable params: 0\n",
    "_________________________________________________________________\n",
    "```\n",
    "\n",
    "### Explication du Résumé\n",
    "\n",
    "- **Output Shape** : Indique la forme de la sortie de chaque couche. Par exemple, après la couche Flatten, la sortie est un vecteur de dimension `(None, 784)`, où `None` représente la taille du lot.\n",
    "- **Param #** : Montre le nombre total de paramètres à entraîner dans chaque couche. Par exemple, pour la couche Dense avec 128 neurones, le nombre de paramètres est de \\( 784 \\times 128 + 128 = 100480 \\).\n",
    "\n",
    "---\n",
    "\n",
    "### Code Complet pour la Construction et Compilation du Modèle\n",
    "\n",
    "Voici le code intégral pour construire et compiler le modèle de réseau de neurones :\n",
    "\n",
    "```python\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "\n",
    "# Construction du modèle\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=(28, 28)),       # Couche d'entrée\n",
    "    Dense(128, activation='relu'),       # Couche cachée\n",
    "    Dense(10, activation='softmax')      # Couche de sortie\n",
    "])\n",
    "\n",
    "# Compilation du modèle\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Afficher le résumé du modèle\n",
    "model.summary()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "Le modèle est maintenant prêt à être entraîné avec les données !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cde11899-7789-4738-848e-a80907fce7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A vous de jouer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da5c398-ac66-4b2a-9b54-e2394b4574d3",
   "metadata": {},
   "source": [
    "## Entraînement et Évaluation du Modèle\n",
    "\n",
    "Une fois que notre modèle de réseau de neurones est construit et compilé, nous pouvons procéder à l’entraînement et ensuite à l’évaluation pour mesurer ses performances sur le jeu de données de test.\n",
    "\n",
    "### 1. Entraînement du Modèle\n",
    "\n",
    "L’entraînement du modèle consiste à ajuster ses paramètres (poids et biais) pour minimiser l’erreur de prédiction. Nous utilisons la méthode `fit()` de Keras pour entraîner le modèle sur le jeu de données d’entraînement. \n",
    "\n",
    "```python\n",
    "# Entraînement du modèle\n",
    "history = model.fit(x_train, y_train, epochs=5, validation_split=0.2)\n",
    "```\n",
    "\n",
    "- **`epochs=5`** : Nombre de passes complètes sur l'ensemble des données d'entraînement. Vous pouvez augmenter ce nombre pour améliorer la performance, mais au risque d'un surapprentissage (*overfitting*).\n",
    "- **`validation_split=0.2`** : Fraction des données d’entraînement utilisée pour la validation (20% ici). Cela permet de surveiller la performance du modèle sur des données qu’il n’a pas encore vues.\n",
    "\n",
    "Le `history` contient les métriques d'entraînement et de validation pour chaque epochs, ce qui permet de visualiser l’évolution de la perte et de la précision.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Évaluation du Modèle\n",
    "\n",
    "Une fois le modèle entraîné, on évalue ses performances sur le jeu de données de test. Cela nous donne une mesure de la capacité du modèle à généraliser, c’est-à-dire à faire des prédictions précises sur des données nouvelles.\n",
    "\n",
    "```python\n",
    "# Évaluation du modèle sur les données de test\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print('\\nPrécision sur les données de test :', test_acc)\n",
    "```\n",
    "\n",
    "- **`test_loss`** : Valeur de la fonction de perte sur le jeu de données de test.\n",
    "- **`test_acc`** : Précision du modèle sur le jeu de données de test, soit le pourcentage de prédictions correctes.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Visualisation des Courbes d'Entraînement et de Validation\n",
    "\n",
    "Il est souvent utile de visualiser la courbe de perte et de précision pour comprendre comment le modèle a appris au fil des epochs. Cela permet de détecter des problèmes de surapprentissage (si la perte de validation augmente alors que la perte d’entraînement continue de diminuer).\n",
    "\n",
    "```python\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Récupérer l'historique d'entraînement\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "train_acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "# Visualiser la perte\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_loss, label='Perte d\\'entraînement')\n",
    "plt.plot(val_loss, label='Perte de validation')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Perte')\n",
    "plt.legend()\n",
    "plt.title('Courbe de Perte')\n",
    "\n",
    "# Visualiser la précision\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_acc, label='Précision d\\'entraînement')\n",
    "plt.plot(val_acc, label='Précision de validation')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Précision')\n",
    "plt.legend()\n",
    "plt.title('Courbe de Précision')\n",
    "\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "- **Courbe de Perte** : Permet de voir si le modèle converge (diminution de la perte) et si la perte de validation est plus élevée que celle de l'entraînement, signe possible de surapprentissage.\n",
    "- **Courbe de Précision** : Indique comment la précision s'améliore avec les epochs et si le modèle atteint un plateau.\n",
    "\n",
    "---\n",
    "\n",
    "### Code Complet pour Entraînement et Évaluation\n",
    "\n",
    "```python\n",
    "# Entraînement du modèle\n",
    "history = model.fit(x_train, y_train, epochs=5, validation_split=0.2)\n",
    "\n",
    "# Évaluation du modèle\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print('\\nPrécision sur les données de test :', test_acc)\n",
    "\n",
    "# Visualisation des courbes d'entraînement et de validation\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "train_acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Courbe de Perte\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_loss, label='Perte d\\'entraînement')\n",
    "plt.plot(val_loss, label='Perte de validation')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Perte')\n",
    "plt.legend()\n",
    "plt.title('Courbe de Perte')\n",
    "\n",
    "# Courbe de Précision\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_acc, label='Précision d\\'entraînement')\n",
    "plt.plot(val_acc, label='Précision de validation')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Précision')\n",
    "plt.legend()\n",
    "plt.title('Courbe de Précision')\n",
    "\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Interprétation des Résultats\n",
    "\n",
    "- **Précision sur les données de test** : Un indicateur de la performance du modèle sur des données non vues.\n",
    "- **Courbes de perte et de précision** : Permettent d’observer si le modèle surapprend ou sous-apprend. Si la perte d'entraînement est nettement inférieure à la perte de validation, cela peut indiquer que le modèle surapprend et pourrait bénéficier de régularisation ou de plus de données d’entraînement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02276844-3129-402a-bcb0-4814e3feb313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A vous de jouer "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909804c8-e4a4-463c-abd6-217bf6cc6ba3",
   "metadata": {},
   "source": [
    "### Overfitting\n",
    "\n",
    "![Exemple de courbes de perte et de précision](surapprentissage_mlp_tf.png)\n",
    "\n",
    "En examinant les courbes de perte et de précision ci-dessus, on constate que :\n",
    "\n",
    "1. **Courbe de Perte** :\n",
    "   - La perte d'entraînement diminue régulièrement, ce qui est un bon signe : le modèle apprend à réduire l'erreur sur l'ensemble d'entraînement.\n",
    "   - Cependant, la perte de validation est relativement stable et même légèrement plus élevée que la perte d'entraînement. Cela peut être un signe de **surapprentissage** (overfitting), où le modèle s'adapte trop aux données d'entraînement et ne généralise pas aussi bien sur les données de validation.\n",
    "\n",
    "2. **Courbe de Précision** :\n",
    "   - La précision d'entraînement augmente progressivement, ce qui est cohérent avec la diminution de la perte d'entraînement.\n",
    "   - La précision de validation, en revanche, reste relativement stable et inférieure à la précision d'entraînement. Cela confirme également une certaine forme de surapprentissage, car le modèle performe mieux sur l'entraînement que sur la validation.\n",
    "\n",
    "### Suggestions d'Amélioration\n",
    "\n",
    "1. **Régularisation** :\n",
    "   - Vous pouvez ajouter une régularisation L2 dans les couches `Dense` ou ajouter des **couches de Dropout** pour aider à réduire le surapprentissage. Par exemple, en ajoutant une couche `Dropout` après la couche cachée :\n",
    "\n",
    "     ```python\n",
    "     from tensorflow.keras.layers import Dropout\n",
    "     \n",
    "     model = keras.Sequential([\n",
    "         keras.layers.Flatten(input_shape=(28, 28)),\n",
    "         keras.layers.Dense(128, activation='relu'),\n",
    "         Dropout(0.5),  # Couche de Dropout pour régularisation\n",
    "         keras.layers.Dense(10, activation='softmax')\n",
    "     ])\n",
    "     ```\n",
    "\n",
    "2. **Plus de Données ou Augmentation de Données** :\n",
    "   - Si possible, vous pouvez augmenter la taille de votre ensemble d'entraînement en appliquant de la **data augmentation** (rotation, zoom, etc.) pour créer de la diversité dans les images, même si cela est généralement plus pertinent pour des images plus complexes.\n",
    "\n",
    "3. **Réduction de la Complexité du Modèle** :\n",
    "   - Si le modèle est trop complexe par rapport à la taille de l'ensemble de données, cela peut aussi causer du surapprentissage. Vous pouvez essayer de réduire le nombre de neurones dans la couche cachée.\n",
    "\n",
    "4. **Epochs** :\n",
    "   - Vous pourriez également expérimenter avec un nombre différent d'Epochs pour voir si un entraînement plus court ou plus long donne de meilleurs résultats sur la validation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b87f83-c21b-4d49-8e14-9a61f7e7e14f",
   "metadata": {},
   "source": [
    "## Prédictions avec le Modèle de Réseau de Neurones\n",
    "\n",
    "Une fois que le modèle est bien entraîné et évalué, nous pouvons l’utiliser pour faire des prédictions sur de nouvelles données. Dans cet exemple, nous allons effectuer des prédictions sur l’ensemble de test pour vérifier comment le modèle se comporte sur des données qu’il n’a jamais vues pendant l’entraînement.\n",
    "\n",
    "### 1. Faire des Prédictions\n",
    "\n",
    "Pour faire des prédictions, nous utilisons la méthode `predict()` de Keras. Cette méthode retourne un tableau de probabilités pour chaque classe (de 0 à 9 dans le cas de MNIST).\n",
    "\n",
    "```python\n",
    "# Faire des prédictions sur l'ensemble de test\n",
    "predictions = model.predict(x_test)\n",
    "```\n",
    "\n",
    "Chaque élément de `predictions` contient les probabilités pour chaque classe (10 probabilités pour chaque chiffre de 0 à 9). Pour obtenir la classe prédite, on peut utiliser `np.argmax()` pour trouver l'indice de la probabilité la plus élevée.\n",
    "\n",
    "### 2. Afficher les Prédictions avec les Images\n",
    "\n",
    "Nous allons visualiser quelques images de l’ensemble de test avec leurs étiquettes réelles et les prédictions du modèle. Cela permet de vérifier si le modèle prédit correctement les chiffres.\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Affichage des premières images de l'ensemble de test avec leurs prédictions\n",
    "num_images = 10\n",
    "plt.figure(figsize=(12, 2))\n",
    "for i in range(num_images):\n",
    "    plt.subplot(1, num_images, i + 1)\n",
    "    plt.imshow(x_test[i], cmap='gray')\n",
    "    plt.axis('off')\n",
    "    predicted_label = np.argmax(predictions[i])\n",
    "    true_label = y_test[i]\n",
    "    color = 'green' if predicted_label == true_label else 'red'\n",
    "    plt.title(f\"Préd: {predicted_label}\\nRéel: {true_label}\", color=color)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "- **Légende de l'image** : Chaque image montre la **prédiction du modèle** et **l'étiquette réelle**.\n",
    "- **Couleur du texte** : La prédiction est affichée en vert si elle est correcte et en rouge si elle est incorrecte, pour faciliter la distinction.\n",
    "\n",
    "### 3. Vérifier la Précision des Prédictions\n",
    "\n",
    "Pour obtenir une vue d’ensemble de la performance du modèle sur l’ensemble de test, nous pouvons calculer la **précision globale** des prédictions :\n",
    "\n",
    "```python\n",
    "# Calcul de la précision sur l'ensemble de test\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "accuracy = np.mean(predicted_labels == y_test)\n",
    "print(f\"Précision des prédictions sur l'ensemble de test : {accuracy * 100:.2f}%\")\n",
    "```\n",
    "\n",
    "Cela calcule le pourcentage de prédictions correctes en comparant les étiquettes prédites et les étiquettes réelles de l'ensemble de test.\n",
    "\n",
    "---\n",
    "\n",
    "### Code Complet pour les Prédictions et Visualisations\n",
    "\n",
    "Voici le code complet pour faire des prédictions, afficher des exemples d'images avec les prédictions, et calculer la précision globale sur l'ensemble de test :\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Faire des prédictions sur l'ensemble de test\n",
    "predictions = model.predict(x_test)\n",
    "\n",
    "# Affichage des premières images avec leurs prédictions\n",
    "num_images = 10\n",
    "plt.figure(figsize=(12, 2))\n",
    "for i in range(num_images):\n",
    "    plt.subplot(1, num_images, i + 1)\n",
    "    plt.imshow(x_test[i], cmap='gray')\n",
    "    plt.axis('off')\n",
    "    predicted_label = np.argmax(predictions[i])\n",
    "    true_label = y_test[i]\n",
    "    color = 'green' if predicted_label == true_label else 'red'\n",
    "    plt.title(f\"Préd: {predicted_label}\\nRéel: {true_label}\", color=color)\n",
    "plt.show()\n",
    "\n",
    "# Calcul de la précision des prédictions sur l'ensemble de test\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "accuracy = np.mean(predicted_labels == y_test)\n",
    "print(f\"Précision des prédictions sur l'ensemble de test : {accuracy * 100:.2f}%\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Interprétation des Résultats\n",
    "\n",
    "- **Images Prédictions Correctes/Incorrectes** : Les images annotées en vert indiquent que le modèle a prédit correctement, tandis que celles en rouge indiquent des erreurs de prédiction.\n",
    "- **Précision Globale** : La précision globale sur l'ensemble de test permet d'avoir un aperçu quantitatif des performances du modèle.\n",
    "\n",
    "Ce code vous permet de vérifier visuellement et numériquement la performance du modèle sur de nouvelles données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94df812e-54ce-4c47-99b7-ea612d98b76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A vous de jouer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99858d05-7ba1-42e0-8cc5-3c2cd0b13f97",
   "metadata": {},
   "source": [
    "# Exercice\n",
    "\n",
    "Créez et optimisez un modèle de réseau de neuronnes pour prédire les classes d'images en utilisant les données de votre choix parmi ceux d'Image Classification dans les datasets de TensorFlow : https://www.tensorflow.org/datasets/catalog/beans?hl=fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda8b28a-d800-47eb-a99e-9cea39120c13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
