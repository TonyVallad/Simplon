{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6d1c139-1f01-4424-a9ac-07de73034c4e",
   "metadata": {},
   "source": [
    "### **Qu'est-ce qu'un CNN ?**\n",
    "\n",
    "Un réseau de neurones convolutionnel est un type de réseau de neurones profond spécifiquement conçu pour traiter des données ayant une structure en grille, comme les images. Les CNN sont particulièrement efficaces pour les tâches de vision par ordinateur telles que la classification d'images, la détection d'objets et la reconnaissance de visages.\n",
    "\n",
    "---\n",
    "\n",
    "### **Principaux composants d'un CNN**\n",
    "\n",
    "1. **Couche de convolution**\n",
    "   - **Filtres (ou noyaux)** : petits matrices de poids appliquées sur l'entrée.\n",
    "   - **Opération de convolution** : consiste à faire glisser le filtre sur l'entrée pour produire une carte de caractéristiques (feature map).\n",
    "   - **Fonction d'activation** : généralement la ReLU (Rectified Linear Unit), qui introduit la non-linéarité.\n",
    "\n",
    "2. **Couche de pooling**\n",
    "   - **But** : réduire la dimensionnalité spatiale des cartes de caractéristiques tout en conservant les informations importantes.\n",
    "   - **Types courants** : max-pooling (prend la valeur maximale), average-pooling (calcule la moyenne).\n",
    "\n",
    "3. **Couches entièrement connectées**\n",
    "   - **Fonction** : chaque neurone est connecté à tous les neurones de la couche précédente.\n",
    "   - **Utilisation** : généralement utilisées à la fin du réseau pour effectuer la classification.\n",
    "\n",
    "---\n",
    "\n",
    "### **Comment fonctionne un CNN ?**\n",
    "\n",
    "1. **Extraction de caractéristiques locales**\n",
    "   - Les couches de convolution détectent des motifs simples (bords, textures) dans les premières couches.\n",
    "   - Les couches plus profondes détectent des motifs plus complexes (formes, objets entiers).\n",
    "\n",
    "2. **Réduction de la dimensionnalité**\n",
    "   - Les couches de pooling diminuent la taille des cartes de caractéristiques, ce qui réduit le nombre de paramètres et contrôle le surapprentissage.\n",
    "\n",
    "3. **Classification**\n",
    "   - Les couches entièrement connectées utilisent les caractéristiques extraites pour prédire la classe de l'entrée.\n",
    "\n",
    "---\n",
    "\n",
    "### **Pourquoi les CNN sont efficaces pour les images ?**\n",
    "\n",
    "- **Partage des poids** : les mêmes filtres sont utilisés sur toute l'image, ce qui réduit le nombre de paramètres.\n",
    "- **Invariance aux translations** : la capacité à reconnaître des motifs indépendamment de leur position dans l'image.\n",
    "- **Hiérarchisation des caractéristiques** : les CNN apprennent des caractéristiques de bas niveau à haut niveau.\n",
    "\n",
    "---\n",
    "\n",
    "### **Exemple simplifié**\n",
    "\n",
    "- **Entrée** : une image de 28x28 pixels (par exemple, un chiffre manuscrit).\n",
    "- **Couche de convolution** : application de plusieurs filtres pour extraire des caractéristiques.\n",
    "- **Fonction d'activation ReLU** : introduction de la non-linéarité.\n",
    "- **Couche de pooling** : réduction de la dimension spatiale.\n",
    "- **Couches entièrement connectées** : classification de l'image en une des classes possibles (par exemple, les chiffres de 0 à 9).\n",
    "\n",
    "---\n",
    "\n",
    "### **Apprentissage des poids**\n",
    "\n",
    "- **Propagation avant** : calcul des sorties du réseau pour une entrée donnée.\n",
    "- **Fonction de perte** : mesure l'écart entre la sortie prédite et la sortie réelle.\n",
    "- **Rétropropagation** : ajustement des poids pour minimiser la fonction de perte en utilisant des algorithmes d'optimisation comme la descente de gradient.\n",
    "\n",
    "---\n",
    "\n",
    "### **Ressources pour approfondir**\n",
    "\n",
    "- **Cours en ligne** : consultez des plateformes comme Coursera ou Udemy pour des cours sur les CNN.\n",
    "- **Livres** : \"Deep Learning\" par Ian Goodfellow, Yoshua Bengio et Aaron Courville.\n",
    "- **Tutoriels pratiques** : expérimentez avec des bibliothèques comme TensorFlow ou PyTorch pour implémenter vos propres CNN.\n",
    "\n",
    "---\n",
    "\n",
    "N'hésitez pas à poser des questions plus spécifiques ou à demander des clarifications sur certains points !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "343ccaa5-8209-4466-b32e-f0d55dff4b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da2a468-d9fd-4f36-98ce-a5b5589bebcd",
   "metadata": {},
   "source": [
    "Pour l’importation des bibliothèques et le chargement des données, les étapes sont similaires à celles d’un réseau de neurones classique.\n",
    "\n",
    "---\n",
    "\n",
    "## Importation des Bibliothèques Nécessaires\n",
    "\n",
    "Pour construire et entraîner un CNN en utilisant TensorFlow et Keras, nous devons d’abord importer les bibliothèques de base. Dans ce tutoriel, nous utiliserons TensorFlow, Numpy pour les manipulations de données, et Matplotlib pour visualiser les images si nécessaire.\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Chargement et prétraitement des Données\n",
    "\n",
    "Pour ce notebook, nous utiliserons le jeu de données **MNIST**.\n",
    "\n",
    "### Exemple 1 : Jeu de Données MNIST (Chiffres manuscrits)\n",
    "\n",
    "MNIST est un jeu de données de chiffres manuscrits (de 0 à 9) en niveaux de gris de taille 28x28 pixels.\n",
    "\n",
    "```python\n",
    "# Charger le jeu de données MNIST\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Normaliser les images\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "\n",
    "# Ajouter une dimension pour le canal (gris) pour que les données soient compatibles avec les couches Conv2D\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "\n",
    "# Encoder les étiquettes en catégories (One-Hot Encoding)\n",
    "num_classes = 10\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "```\n",
    "\n",
    "#### Explications\n",
    "\n",
    "- **Normalisation** : Les valeurs des pixels sont divisées par 255 pour les mettre dans une plage entre 0 et 1, ce qui rend l'entraînement plus stable.\n",
    "- **Ajout d'une dimension** : Les images MNIST sont en niveaux de gris (28x28), donc on ajoute une dimension supplémentaire pour les rendre compatibles avec les couches `Conv2D` de TensorFlow (forme finale : 28x28x1).\n",
    "- **Encodage des étiquettes** : Utilisation de `to_categorical` pour convertir les labels en vecteurs binaires (One-Hot Encoding), car il y a 10 classes pour les chiffres (0-9).\n",
    "\n",
    "### Exemple 2 : Jeu de Données CIFAR-10 (Images couleur de 10 classes)\n",
    "\n",
    "CIFAR-10 est un jeu de données plus complexe contenant des images couleur (32x32) de 10 classes différentes (par exemple, chiens, chats, avions, etc.).\n",
    "\n",
    "```python\n",
    "# Charger le jeu de données CIFAR-10\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Normaliser les images\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "\n",
    "# Encoder les étiquettes en catégories (One-Hot Encoding)\n",
    "num_classes = 10\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "```\n",
    "\n",
    "#### Explications\n",
    "\n",
    "- **Normalisation** : Comme pour MNIST, les valeurs de pixels sont divisées par 255 pour les normaliser entre 0 et 1.\n",
    "- **Pas besoin d’ajouter une dimension** : CIFAR-10 contient déjà des images avec trois canaux de couleur (RGB), donc pas besoin d'ajouter une dimension supplémentaire.\n",
    "- **Encodage des étiquettes** : Conversion des labels en vecteurs binaires pour avoir une sortie de 10 dimensions pour les 10 classes.\n",
    "\n",
    "---\n",
    "\n",
    "## Visualisation des Images (Optionnel)\n",
    "\n",
    "Pour vérifier le bon chargement des données, vous pouvez visualiser quelques images du jeu de données en utilisant `matplotlib`.\n",
    "\n",
    "```python\n",
    "# Afficher quelques exemples d'images et leurs étiquettes\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(9):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(x_train[i].squeeze(), cmap=\"gray\" if x_train.shape[-1] == 1 else None)\n",
    "    plt.title(f\"Étiquette : {np.argmax(y_train[i])}\")\n",
    "    plt.axis(\"off\")\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "Cette section est optionnelle mais peut être utile pour vérifier que les données sont correctement chargées et prétraitées.\n",
    "\n",
    "---\n",
    "\n",
    "## Résumé\n",
    "\n",
    "1. **Importation des Bibliothèques** : Importation de TensorFlow, Keras, NumPy, et Matplotlib.\n",
    "2. **Chargement des Données** : Utilisation des datasets MNIST ou CIFAR-10 pour l'entraînement.\n",
    "3. **Prétraitement** : Normalisation des images, ajustement de la forme pour les couches convolutives, et encodage des étiquettes.\n",
    "4. **Visualisation (optionnelle)** : Vérification visuelle des images pour valider le chargement des données.\n",
    "\n",
    "Avec ces étapes, vous avez maintenant toutes les données prêtes pour être utilisées dans le CNN, qu'il s'agisse d'un réseau simple ou convolutif."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8a88361-40b6-46a3-ab19-86768207f05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A vous de jouer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3843ab-8180-4ab0-b42d-e0a886fef002",
   "metadata": {},
   "source": [
    "Expliquons la construction de ce modèle CNN étape par étape. Ce modèle est conçu pour traiter des images en niveaux de gris de taille 28x28 pixels et les classer en différentes catégories (par exemple, des chiffres de 0 à 9 dans le cas de MNIST).\n",
    "\n",
    "### Code Complet\n",
    "\n",
    "```python\n",
    "model = keras.Sequential([\n",
    "    keras.Input(shape=(28, 28, 1)),\n",
    "    layers.Conv2D(32, kernel_size=(3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    layers.Flatten(),\n",
    "    #layers.Dropout(0.5),\n",
    "    \n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "```\n",
    "\n",
    "### Étapes de la Construction\n",
    "\n",
    "#### 1. `keras.Input(shape=(28, 28, 1))`\n",
    "- **Définition de la forme d'entrée** : Ici, nous spécifions que le modèle prend en entrée des images de taille 28x28 pixels avec 1 canal (images en niveaux de gris).\n",
    "- **Objectif** : Cette couche d'entrée fixe la forme des données en entrée et est particulièrement utile dans les modèles `Sequential`.\n",
    "\n",
    "#### 2. `layers.Conv2D(32, kernel_size=(3, 3), activation='relu')`\n",
    "- **Couche Convolutive** : Cette couche applique 32 filtres de convolution de taille 3x3 sur l'image d'entrée.\n",
    "- **Activation ReLU** : `ReLU` (Rectified Linear Unit) est appliqué pour ajouter de la non-linéarité et accélérer l'entraînement.\n",
    "- **Objectif** : La couche convolutive aide à extraire des caractéristiques locales de l'image, telles que des bords ou des textures, en utilisant les filtres pour détecter différentes parties de l'image.\n",
    "\n",
    "#### 3. `layers.MaxPooling2D(pool_size=(2, 2))`\n",
    "- **Couche de Max Pooling** : Cette couche réduit la taille de l'image en prenant le maximum dans chaque région 2x2.\n",
    "- **Objectif** : Le pooling réduit la dimension de la carte de caractéristiques tout en conservant les informations les plus importantes. Cela permet de réduire le nombre de paramètres et de contrôler le surapprentissage.\n",
    "\n",
    "#### 4. `layers.Conv2D(64, kernel_size=(3, 3), activation='relu')`\n",
    "- **Deuxième Couche Convolutive** : Cette couche applique 64 filtres de convolution 3x3 sur la sortie de la première couche de pooling.\n",
    "- **Activation ReLU** : Encore une fois, `ReLU` est appliqué pour introduire de la non-linéarité.\n",
    "- **Objectif** : Cette deuxième couche convolutive permet d'extraire des caractéristiques plus complexes et abstraites de l'image.\n",
    "\n",
    "#### 5. `layers.MaxPooling2D(pool_size=(2, 2))`\n",
    "- **Deuxième Couche de Max Pooling** : Comme précédemment, cette couche réduit la taille de la carte de caractéristiques en appliquant un pooling 2x2.\n",
    "- **Objectif** : Réduire davantage la dimension de la carte de caractéristiques pour diminuer le nombre de paramètres du modèle, tout en conservant les caractéristiques les plus importantes.\n",
    "\n",
    "#### 6. `layers.Flatten()`\n",
    "- **Aplatissement des Données** : Cette couche transforme la carte de caractéristiques multidimensionnelle en un vecteur unidimensionnel.\n",
    "- **Objectif** : Cette étape est nécessaire pour passer des couches convolutives (2D) aux couches entièrement connectées (1D), qui attendent des vecteurs en entrée.\n",
    "\n",
    "#### 7. `#layers.Dropout(0.5)`\n",
    "- **(Optionnel) Couche Dropout** : Commentée dans ce code, cette couche est utilisée pour éviter le surapprentissage en désactivant aléatoirement 50% des neurones pendant l'entraînement.\n",
    "- **Objectif** : Dropout est une technique de régularisation qui aide à généraliser le modèle en le rendant moins dépendant de certaines caractéristiques spécifiques.\n",
    "\n",
    "#### 8. `layers.Dense(128, activation='relu')`\n",
    "- **Couche Dense (Entièrement Connectée)** : Cette couche contient 128 neurones connectés à tous les neurones de la couche précédente.\n",
    "- **Activation ReLU** : ReLU est appliqué ici pour introduire de la non-linéarité.\n",
    "- **Objectif** : Combiner les caractéristiques extraites par les couches convolutives pour former des représentations plus complexes.\n",
    "\n",
    "#### 9. `layers.Dense(num_classes, activation='softmax')`\n",
    "- **Couche de Sortie** : Cette couche entièrement connectée finale a un nombre de neurones égal au nombre de classes (`num_classes`), avec une fonction d'activation **softmax**.\n",
    "- **Activation Softmax** : Softmax normalise les sorties pour représenter des probabilités pour chaque classe.\n",
    "- **Objectif** : Fournir les prédictions de probabilité pour chaque classe. La classe ayant la probabilité la plus élevée sera choisie comme prédiction du modèle.\n",
    "\n",
    "### Résumé\n",
    "\n",
    "- **Partie Convolutive** : Les deux premières couches `Conv2D` et `MaxPooling2D` sont utilisées pour extraire des caractéristiques importantes de l'image d'entrée. La première couche convolutive détecte des caractéristiques simples (par exemple, des bords), et la seconde couche convolutive détecte des caractéristiques plus complexes (par exemple, des motifs).\n",
    "- **Partie Aplatissement et Dense** : Après avoir extrait les caractéristiques, elles sont aplaties en un vecteur et passées à des couches entièrement connectées, qui combinent les informations pour faire une prédiction.\n",
    "- **Sortie Softmax** : Fournit des probabilités pour chaque classe cible.\n",
    "\n",
    "Ce modèle CNN est simple mais suffisant pour des tâches de classification d'images comme MNIST ou CIFAR-10. Il est efficace pour capturer les caractéristiques importantes de l'image, les combiner et effectuer une classification en utilisant la dernière couche dense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d85387a-b4e5-44ba-9a21-db872622aa66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A vous de jouer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8675d53-eb24-49ea-b4c2-fb8d2eb87029",
   "metadata": {},
   "source": [
    "La compilation d'un modèle dans Keras consiste à définir les configurations nécessaires à son entraînement, notamment en spécifiant l'optimiseur, la fonction de perte et les métriques d'évaluation. Voyons en détail les paramètres utilisés dans la fonction `compile` de Keras, avec des explications sur les choix possibles pour chaque paramètre, et quand les utiliser ou non.\n",
    "\n",
    "### Exemple de Code de Compilation\n",
    "\n",
    "```python\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "```\n",
    "\n",
    "### Paramètres de `compile`\n",
    "\n",
    "1. **`optimizer` (Optimiseur)**  \n",
    "   L’optimiseur contrôle le processus d’apprentissage du modèle en ajustant les poids du réseau pour minimiser la fonction de perte. Voici quelques optimiseurs populaires et des recommandations pour leur utilisation :\n",
    "\n",
    "   - **`sgd` (Stochastic Gradient Descent)** : L’optimiseur de descente de gradient stochastique classique. Il est simple et peut être efficace pour des petits datasets ou des modèles de petite taille.\n",
    "     - **Pratique** : Lorsque le modèle est simple et que la vitesse d'apprentissage doit être maîtrisée (modèles peu profonds).\n",
    "     - **Moins Pratique** : Pour des modèles profonds et des datasets complexes, car il peut être lent et avoir des difficultés à sortir des minima locaux.\n",
    "\n",
    "   - **`adam` (Adaptive Moment Estimation)** : L’un des optimiseurs les plus populaires, car il combine les avantages de `RMSprop` et `Momentum`. Il adapte automatiquement le taux d'apprentissage.\n",
    "     - **Pratique** : Convient aux modèles profonds et pour la plupart des tâches de deep learning. Il est généralement un bon choix par défaut pour de nombreux modèles.\n",
    "     - **Moins Pratique** : Peut surapprendre rapidement si le taux d'apprentissage n’est pas bien ajusté, notamment sur des datasets de petite taille.\n",
    "\n",
    "   - **`rmsprop`** : Un optimiseur adapté aux réseaux de neurones récurrents et aux données séquentielles.\n",
    "     - **Pratique** : Très efficace pour les RNN et LSTM. Bon pour des données séquentielles ou de séries temporelles.\n",
    "     - **Moins Pratique** : Moins efficace pour des modèles de vision par ordinateur par rapport à `adam`.\n",
    "\n",
    "   - **`adagrad`** : Un optimiseur avec un taux d’apprentissage adaptatif, utile pour des problèmes de sparsité.\n",
    "     - **Pratique** : Pour les modèles travaillant avec des données très creuses (ex. traitement de texte).\n",
    "     - **Moins Pratique** : Le taux d'apprentissage peut diminuer trop rapidement, rendant l'entraînement moins efficace pour des modèles profonds.\n",
    "\n",
    "   > **Remarque** : L'optimiseur `adam` est souvent un bon choix par défaut pour les modèles CNN, car il est rapide et fonctionne bien dans la plupart des situations.\n",
    "\n",
    "2. **`loss` (Fonction de Perte)**  \n",
    "   La fonction de perte mesure l'erreur entre les prédictions du modèle et les valeurs réelles. Elle guide l'optimiseur pour ajuster les poids du modèle. Le choix de la fonction de perte dépend du type de tâche :\n",
    "\n",
    "   - **`categorical_crossentropy`** : Utilisée pour les problèmes de classification multi-classes avec des étiquettes encodées en one-hot (comme les images de chiffres 0-9 dans MNIST).\n",
    "     - **Pratique** : Lorsque les labels sont dans une forme one-hot et qu'il y a plus de deux classes.\n",
    "     - **Moins Pratique** : Non adaptée pour les problèmes de classification binaire ou lorsque les labels ne sont pas one-hot.\n",
    "\n",
    "   - **`binary_crossentropy`** : Utilisée pour la classification binaire (deux classes).\n",
    "     - **Pratique** : Pour les problèmes de classification binaire, où chaque exemple appartient à l'une des deux classes.\n",
    "     - **Moins Pratique** : Pour les classifications multi-classes ou les régressions.\n",
    "\n",
    "   - **`sparse_categorical_crossentropy`** : Semblable à `categorical_crossentropy`, mais utilisée lorsque les étiquettes ne sont pas encodées en one-hot.\n",
    "     - **Pratique** : Pour les problèmes de classification multi-classes où les labels sont des entiers.\n",
    "     - **Moins Pratique** : Inutile si les étiquettes sont déjà en one-hot (dans ce cas, utilisez `categorical_crossentropy`).\n",
    "\n",
    "   - **`mean_squared_error` (MSE)** : Couramment utilisée pour les tâches de régression, elle mesure la moyenne des erreurs au carré.\n",
    "     - **Pratique** : Pour les problèmes de régression, où l’objectif est de minimiser la différence entre les valeurs prédites et réelles.\n",
    "     - **Moins Pratique** : Pas adaptée pour les tâches de classification, car elle ne prend pas en compte la probabilité.\n",
    "\n",
    "   > **Remarque** : Pour un CNN de classification multi-classes, comme celui-ci, `categorical_crossentropy` est approprié si les labels sont encodés en one-hot. Si vos labels sont des entiers, `sparse_categorical_crossentropy` serait plus adapté.\n",
    "\n",
    "3. **`metrics` (Métriques)**  \n",
    "   Les métriques fournissent une évaluation supplémentaire pour suivre les performances du modèle lors de l’entraînement et de l’évaluation. La métrique couramment utilisée pour les modèles de classification est `accuracy`.\n",
    "\n",
    "   - **`accuracy`** : Représente la proportion de prédictions correctes.\n",
    "     - **Pratique** : Pour la plupart des problèmes de classification, `accuracy` donne une bonne indication de la performance.\n",
    "     - **Moins Pratique** : Pour les problèmes de classification déséquilibrés (où une classe est beaucoup plus fréquente), `accuracy` peut être trompeuse. Dans ces cas, des métriques comme la **précision** (precision), le **rappel** (recall) ou le **F1-score** sont plus pertinentes.\n",
    "\n",
    "   - **`precision` et `recall`** : La précision mesure la proportion de vraies prédictions positives parmi toutes les prédictions positives, tandis que le rappel mesure la proportion de vraies prédictions positives parmi toutes les vraies positives.\n",
    "     - **Pratique** : Utile pour les ensembles de données déséquilibrés ou les applications où les faux positifs ou faux négatifs ont des conséquences importantes.\n",
    "     - **Moins Pratique** : Pas nécessaire pour des ensembles de données équilibrés ou des problèmes où l’accuracy suffit pour évaluer les performances.\n",
    "\n",
    "   - **`AUC` (Area Under the Curve)** : Utile pour évaluer les modèles de classification binaire. Il mesure la capacité du modèle à différencier entre les classes positives et négatives.\n",
    "     - **Pratique** : Pour les problèmes de classification binaire avec des données déséquilibrées.\n",
    "     - **Moins Pratique** : Non pertinent pour les problèmes de classification multi-classes.\n",
    "\n",
    "   > **Remarque** : Pour un problème de classification multi-classes, `accuracy` est généralement la métrique par défaut. Si les données sont déséquilibrées, vous pourriez envisager d'ajouter des métriques supplémentaires comme `precision`, `recall` ou `F1-score` pour des évaluations plus nuancées.\n",
    "\n",
    "---\n",
    "\n",
    "### Exemple de Configuration Avancée\n",
    "\n",
    "Si vous travaillez sur un problème de classification multi-classes avec des étiquettes sous forme d'entiers (non one-hot) et que vous souhaitez surveiller la précision et le rappel, voici comment vous pourriez configurer la compilation :\n",
    "\n",
    "```python\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),  # Taux d'apprentissage ajusté\n",
    "    loss='sparse_categorical_crossentropy',                   # Pour des étiquettes entières\n",
    "    metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n",
    ")\n",
    "```\n",
    "\n",
    "- **`tf.keras.optimizers.Adam(learning_rate=0.001)`** : Ici, nous ajustons le taux d'apprentissage de `Adam` à 0.001, ce qui peut être utile pour éviter un surapprentissage.\n",
    "- **`sparse_categorical_crossentropy`** : Utilisée si les labels sont des entiers (non one-hot).\n",
    "- **`metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]`** : En plus de la précision globale, nous ajoutons les métriques `Precision` et `Recall` pour avoir une idée plus complète des performances.\n",
    "\n",
    "---\n",
    "\n",
    "En résumé, la configuration de la compilation dépend fortement du type de tâche (classification binaire, multi-classes, régression) et de la nature des données. Adapter correctement ces paramètres garantit que le modèle apprendra de manière optimale et que les métriques utilisées seront pertinentes pour évaluer les performances réelles du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a847cfd-8620-407a-b376-b17fac6a2085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A vous de jouer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fde5f3c-17d5-42b6-96cd-259e49ce561d",
   "metadata": {},
   "source": [
    "L'entraînement d'un modèle dans Keras consiste à exécuter le processus d'apprentissage sur un ensemble de données en utilisant la fonction `fit`. Lors de l'entraînement, le modèle ajuste ses poids pour minimiser la fonction de perte spécifiée lors de la compilation. Cette section explique comment utiliser la fonction `fit` avec différents paramètres pour entraîner le modèle, et quelles options sont disponibles pour optimiser l'apprentissage.\n",
    "\n",
    "### Exemple de Code d'Entraînement\n",
    "\n",
    "```python\n",
    "history = model.fit(\n",
    "    x_train,              # Données d'entraînement\n",
    "    y_train,              # Labels d'entraînement\n",
    "    batch_size=128,       # Taille du batch\n",
    "    epochs=10,            # Nombre d'epochs\n",
    "    validation_split=0.1, # Fraction de validation\n",
    "    callbacks=[early_stopping]  # Callbacks (optionnel)\n",
    ")\n",
    "```\n",
    "\n",
    "### Paramètres de `fit`\n",
    "\n",
    "1. **`x` (ou `x_train`) et `y` (ou `y_train`)**\n",
    "   - **Description** : Ce sont les données d'entrée et leurs labels respectifs.\n",
    "   - **Utilisation** : \n",
    "     - **x_train** : contient les images ou données d'entraînement.\n",
    "     - **y_train** : contient les labels ou classes des données d'entraînement.\n",
    "   - **Format** : `x_train` doit être sous forme de tableau (ou tenseur) de taille `(nombre_d'échantillons, hauteur, largeur, canaux)`, par exemple `(60000, 28, 28, 1)` pour MNIST. `y_train` est typiquement un tableau d'étiquettes correspondant.\n",
    "\n",
    "2. **`batch_size`**\n",
    "   - **Description** : Nombre d'échantillons traités avant que le modèle ne mette à jour ses poids.\n",
    "   - **Pratique** : La taille de batch influe sur la vitesse d’entraînement et la stabilité de la convergence.\n",
    "   - **Recommandations** :\n",
    "     - **Petites tailles de batch** (ex. 16, 32) : Souvent utilisées lorsque les données sont limitées ou pour capturer des petites variations dans les gradients. Cela peut ralentir l’entraînement, mais aussi réduire les oscillations dans la descente de gradient.\n",
    "     - **Grandes tailles de batch** (ex. 128, 256) : Utiles pour des grandes quantités de données. Cela accélère l’entraînement mais peut consommer beaucoup de mémoire et réduire la capacité de généralisation du modèle.\n",
    "   - **Exemple** : Dans cet exemple, nous avons choisi `batch_size=128`, ce qui est un bon compromis entre vitesse et précision pour des images de taille modérée comme celles de MNIST.\n",
    "\n",
    "3. **`epochs`**\n",
    "   - **Description** : Nombre de fois que le modèle parcourt l’ensemble des données d’entraînement.\n",
    "   - **Pratique** : Choisir un nombre d’epochs adéquat permet de maximiser les performances sans surentraîner le modèle.\n",
    "   - **Recommandations** :\n",
    "     - Commencez avec un nombre modéré (ex. 10-20 epochs) et ajustez en fonction de la performance.\n",
    "     - Utilisez un `EarlyStopping` pour arrêter l'entraînement quand la perte de validation ne s’améliore plus, même avant d'atteindre le nombre maximal d’epochs.\n",
    "   - **Exemple** : Ici, `epochs=10` est défini, mais si le modèle commence à surapprendre, l’entraînement s'arrêtera plus tôt grâce au `callback`.\n",
    "\n",
    "4. **`validation_split`**\n",
    "   - **Description** : Fraction des données d’entraînement utilisée pour l'évaluation de la validation. Par exemple, `validation_split=0.1` signifie que 10 % des données d’entraînement seront utilisées pour la validation.\n",
    "   - **Pratique** :\n",
    "     - **Pratique** : Pour obtenir une évaluation en temps réel de la performance sur des données non vues par le modèle sans utiliser un ensemble de test séparé.\n",
    "     - **Non Pratique** : Si les données sont limitées ou si vous disposez déjà d'un ensemble de validation distinct.\n",
    "   - **Exemple** : Dans cet exemple, `validation_split=0.1` est utilisé, ce qui laisse 90 % des données pour l’entraînement et 10 % pour la validation.\n",
    "\n",
    "5. **`callbacks`**\n",
    "   - **Description** : Liste de fonctions de rappel exécutées à la fin de chaque epoch ou lorsque certaines conditions sont remplies. Les callbacks peuvent inclure `EarlyStopping`, `ModelCheckpoint`, `ReduceLROnPlateau`, etc.\n",
    "   - **Utilisation commune** :\n",
    "     - **EarlyStopping** : Arrête l’entraînement lorsque la performance sur l'ensemble de validation cesse de s'améliorer, ce qui aide à éviter le surapprentissage.\n",
    "     - **ModelCheckpoint** : Sauvegarde le modèle lorsque la performance atteint de nouveaux sommets, pratique pour restaurer les meilleurs poids.\n",
    "     - **ReduceLROnPlateau** : Diminue le taux d’apprentissage si la performance cesse de s’améliorer.\n",
    "   - **Exemple** : Ici, nous avons inclus `early_stopping` comme callback pour arrêter l’entraînement lorsque la perte de validation cesse de diminuer.\n",
    "\n",
    "---\n",
    "\n",
    "### Exemple de `EarlyStopping`\n",
    "\n",
    "Pour éviter le surapprentissage, nous avons inclus `EarlyStopping` comme callback. Voici un exemple de configuration :\n",
    "\n",
    "```python\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',    # Surveille la perte de validation\n",
    "    patience=3,            # Arrête l’entraînement après 3 epochs sans amélioration\n",
    "    restore_best_weights=True  # Restaure les poids du meilleur modèle\n",
    ")\n",
    "```\n",
    "\n",
    "### Entraînement Complet avec `EarlyStopping`\n",
    "\n",
    "En combinant tous ces éléments, voici un exemple complet du code d'entraînement :\n",
    "\n",
    "```python\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=128,\n",
    "    epochs=20,               # Fixez un nombre d'epochs élevé pour permettre à EarlyStopping de décider quand arrêter\n",
    "    validation_split=0.1,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "643dadbb-7073-4870-88cb-fcd36318974b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A vous de jouer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d5f149-1ede-4ece-9bd4-88eb063d41fb",
   "metadata": {},
   "source": [
    "### Interprétation des Résultats d'Entraînement\n",
    "\n",
    "Le résultat de l'entraînement sera stocké dans la variable `history`, qui contient des informations sur les pertes et précisions d’entraînement et de validation pour chaque epoch.\n",
    "\n",
    "Pour visualiser ces informations :\n",
    "\n",
    "```python\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Affichage de la perte\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label=\"Perte d'entraînement\")\n",
    "plt.plot(history.history['val_loss'], label=\"Perte de validation\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"Perte\")\n",
    "plt.legend()\n",
    "\n",
    "# Affichage de la précision\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label=\"Précision d'entraînement\")\n",
    "plt.plot(history.history['val_accuracy'], label=\"Précision de validation\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"Précision\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "### Résumé\n",
    "\n",
    "- **Données d’entraînement (`x` et `y`)** : Les données d'entrée et les labels.\n",
    "- **Batch Size** : Contrôle le nombre d’échantillons traités avant de mettre à jour les poids.\n",
    "- **Epochs** : Nombre total de passages sur les données d’entraînement.\n",
    "- **Validation Split** : Fraction des données d'entraînement utilisées pour la validation.\n",
    "- **Callbacks** : Fonctions de rappel pour optimiser l’entraînement (comme `EarlyStopping` pour éviter le surapprentissage).\n",
    "\n",
    "L’entraînement d’un CNN implique généralement de tester différents paramètres pour trouver les valeurs qui donnent les meilleures performances sans surentraînement. En combinant les bonnes valeurs pour `batch_size`, `epochs`, et `callbacks`, vous pouvez optimiser le processus d'apprentissage et obtenir des performances maximales pour votre modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b58d605-7f77-47ae-935a-2730e94972f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A vous de jouer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f2254e-b6ca-484d-9e35-14bb84f21ae5",
   "metadata": {},
   "source": [
    "### Exemple de surapprentissage\n",
    "\n",
    "![Overfitting CNN](overfit_cnn_tf.png)\n",
    "\n",
    "#### Courbe de Perte\n",
    "- **Perte d'entraînement** : La perte d'entraînement diminue de manière régulière au fil des epochs, ce qui est un bon signe indiquant que le modèle apprend bien les caractéristiques des données d'entraînement.\n",
    "- **Perte de validation** : La courbe de validation, cependant, montre des oscillations et une tendance à augmenter légèrement. Cela peut indiquer que le modèle commence à surapprendre, car la perte de validation ne diminue pas de façon cohérente après quelques epochs.\n",
    "\n",
    "#### Courbe de Précision\n",
    "- **Précision d'entraînement** : La précision d’entraînement continue d’augmenter au fil des epochs, atteignant une très haute valeur proche de 0,998, ce qui indique que le modèle s’ajuste bien aux données d'entraînement.\n",
    "- **Précision de validation** : La précision de validation oscille et semble légèrement diminuer vers la fin. Cette tendance, combinée avec la perte de validation, suggère un début de surapprentissage (overfitting).\n",
    "\n",
    "**Conclusion** : Le premier ensemble de courbes indique que le modèle pourrait être en train de surapprendre. Vous pourriez envisager de réduire le nombre d'epochs ou d'utiliser une technique de régularisation comme `Dropout` pour améliorer la généralisation.\n",
    "\n",
    "---\n",
    "\n",
    "### Exemple de bonne généralisation\n",
    "\n",
    "![Généralisation CNN](good_cnn_tf.png)\n",
    "\n",
    "#### Courbe de Perte\n",
    "- **Perte d'entraînement** : La perte d’entraînement diminue rapidement dans les premières epochs et continue de baisser légèrement par la suite.\n",
    "- **Perte de validation** : La perte de validation diminue également de manière cohérente, sans oscillations majeures, ce qui indique que le modèle généralise bien sur les données de validation.\n",
    "\n",
    "#### Courbe de Précision\n",
    "- **Précision d'entraînement** : La précision d'entraînement augmente au fil des epochs, mais semble plafonner autour de 0,98, ce qui est un bon signe, car le modèle n'atteint pas des valeurs extrêmes.\n",
    "- **Précision de validation** : La précision de validation reste légèrement plus élevée que la précision d'entraînement, indiquant une bonne généralisation.\n",
    "\n",
    "**Conclusion** : Le deuxième ensemble de courbes montre un meilleur équilibre entre l’entraînement et la validation. Le modèle semble bien généraliser, sans signes de surapprentissage importants. Cela pourrait être dû à une meilleure configuration, comme l'utilisation de `EarlyStopping` ou d'autres techniques de régularisation.\n",
    "\n",
    "---\n",
    "\n",
    "### Recommandations Générales\n",
    "\n",
    "1. **Surapprentissage dans le premier ensemble** : Si les oscillations persistent dans la validation (comme dans le premier ensemble), vous pourriez :\n",
    "   - Ajouter une couche de `Dropout` pour éviter le surapprentissage.\n",
    "   - Utiliser un callback `EarlyStopping` avec un `patience` plus faible pour arrêter l’entraînement dès que la perte de validation commence à augmenter.\n",
    "   - Réduire le nombre d'epochs si le modèle commence à surapprendre après quelques epochs.\n",
    "\n",
    "2. **Bonne généralisation dans le second ensemble** : Dans le second ensemble, les résultats sont très satisfaisants avec une bonne convergence des courbes de perte et de précision. Si les performances sont suffisantes, vous pouvez conserver cette configuration.\n",
    "\n",
    "3. **Affiner les Hyperparamètres** : Pour obtenir des performances optimales, vous pourriez ajuster :\n",
    "   - Le taux d'apprentissage.\n",
    "   - La taille des couches convolutives et denses.\n",
    "   - Les techniques de régularisation.\n",
    "\n",
    "En résumé, le second modèle semble mieux équilibré et montre une meilleure généralisation. Le premier modèle, en revanche, présente des signes de surapprentissage, ce qui pourrait être amélioré avec des ajustements mineurs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be3557a-72cb-449b-b1e4-9bf2befaa89e",
   "metadata": {},
   "source": [
    "# A vous de jouer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c3788d-8d57-4f31-a463-1a0213578955",
   "metadata": {},
   "source": [
    "L'évaluation du modèle consiste à mesurer les performances sur un ensemble de données de test qui n'a pas été vu par le modèle pendant l'entraînement. Cela permet d'estimer la capacité du modèle à généraliser sur de nouvelles données.\n",
    "\n",
    "Voici les étapes et le code pour évaluer un modèle entraîné dans Keras, avec des explications sur les métriques de performance à utiliser et comment interpréter les résultats.\n",
    "\n",
    "### 1. Évaluation de Base avec la Méthode `evaluate`\n",
    "\n",
    "La méthode `evaluate` dans Keras permet d'obtenir la perte et les métriques (comme la précision) pour l'ensemble de test. \n",
    "\n",
    "```python\n",
    "# Évaluation du modèle sur l'ensemble de test\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
    "print(f'Perte sur l’ensemble de test : {test_loss:.4f}')\n",
    "print(f'Précision sur l’ensemble de test : {test_accuracy * 100:.2f}%')\n",
    "```\n",
    "\n",
    "#### Explications\n",
    "\n",
    "- **`x_test` et `y_test`** : Ce sont les données de test et leurs étiquettes.\n",
    "- **Retourne** : La fonction retourne deux valeurs :\n",
    "  - **`test_loss`** : La perte sur l'ensemble de test, qui mesure l'erreur entre les prédictions du modèle et les vraies valeurs.\n",
    "  - **`test_accuracy`** : La précision sur l'ensemble de test, indiquant la proportion de prédictions correctes.\n",
    "- **Interprétation** : Une perte faible et une précision élevée sur l'ensemble de test indiquent que le modèle généralise bien. Si la précision sur l'ensemble de test est significativement inférieure à celle sur l'ensemble de validation, cela peut indiquer un surapprentissage.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Générer des Prédictions et Analyser les Résultats\n",
    "\n",
    "Pour une analyse plus approfondie, vous pouvez examiner les prédictions individuelles et afficher les erreurs de classification.\n",
    "\n",
    "```python\n",
    "# Génération des prédictions pour l'ensemble de test\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Conversion des prédictions en classes\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)  # Si y_test est en one-hot encoding, sinon utilisez y_test directement\n",
    "```\n",
    "\n",
    "#### Explications\n",
    "\n",
    "- **`y_pred`** : La sortie brute des prédictions sous forme de probabilités pour chaque classe.\n",
    "- **`y_pred_classes`** : Conversion en classes prédites en prenant l'indice de la probabilité la plus élevée.\n",
    "- **`y_true`** : Les vraies classes de `y_test`, après conversion si elles sont en one-hot encoding.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Calculer des Métriques Complémentaires\n",
    "\n",
    "Pour un aperçu plus complet des performances, en particulier sur des classes déséquilibrées, vous pouvez calculer des métriques supplémentaires comme la **matrice de confusion**, la **précision**, le **rappel** et le **score F1**.\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Matrice de confusion\n",
    "conf_matrix = confusion_matrix(y_true, y_pred_classes)\n",
    "print(\"Matrice de confusion :\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Rapport de classification\n",
    "class_report = classification_report(y_true, y_pred_classes)\n",
    "print(\"Rapport de classification :\")\n",
    "print(class_report)\n",
    "```\n",
    "\n",
    "#### Explications\n",
    "\n",
    "- **Matrice de Confusion** : Indique combien de fois chaque classe a été confondue avec d'autres classes. Elle est utile pour identifier les classes où le modèle a du mal.\n",
    "- **Rapport de Classification** : Fournit la précision, le rappel et le score F1 pour chaque classe. Ces métriques sont particulièrement utiles pour les données déséquilibrées :\n",
    "  - **Précision** : Proportion de vraies prédictions positives parmi toutes les prédictions positives.\n",
    "  - **Rappel** : Proportion de vraies prédictions positives parmi toutes les vraies positives.\n",
    "  - **Score F1** : Moyenne harmonique entre la précision et le rappel, utile pour un équilibre entre ces deux métriques.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Visualiser les Erreurs de Classification (Optionnel)\n",
    "\n",
    "Pour mieux comprendre les erreurs, vous pouvez visualiser quelques exemples mal classés.\n",
    "\n",
    "```python\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Identifier les indices des exemples mal classés\n",
    "errors = np.where(y_pred_classes != y_true)[0]\n",
    "\n",
    "# Afficher quelques erreurs\n",
    "plt.figure(figsize=(12, 10))\n",
    "for i, idx in enumerate(errors[:9]):  # Afficher les 9 premières erreurs\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(x_test[idx].squeeze(), cmap=\"gray\")\n",
    "    plt.title(f\"Vrai : {y_true[idx]}, Prédit : {y_pred_classes[idx]}\")\n",
    "    plt.axis(\"off\")\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "#### Explications\n",
    "\n",
    "- **Identification des erreurs** : `np.where(y_pred_classes != y_true)[0]` renvoie les indices des exemples où les prédictions sont incorrectes.\n",
    "- **Affichage des erreurs** : La visualisation de quelques exemples permet de comprendre pourquoi le modèle pourrait avoir des difficultés avec certaines classes. Cela peut aussi mettre en lumière des images ambiguës ou des classes similaires.\n",
    "\n",
    "---\n",
    "\n",
    "### Interprétation des Résultats d'Évaluation\n",
    "\n",
    "- **Perte et Précision sur l’Ensemble de Test** : Si la précision de test est similaire à celle de validation, cela indique que le modèle généralise bien. Si elle est nettement inférieure, il peut y avoir un problème de surapprentissage.\n",
    "- **Matrice de Confusion** : Une matrice de confusion déséquilibrée avec de nombreux faux positifs ou faux négatifs pour certaines classes indique des classes difficiles à distinguer pour le modèle.\n",
    "- **Rapport de Classification** : La précision, le rappel et le score F1 sont utiles pour évaluer les performances pour chaque classe. Un faible rappel ou une faible précision pour certaines classes peut indiquer la nécessité d'un meilleur équilibrage des données ou d'un modèle plus complexe.\n",
    "\n",
    "---\n",
    "\n",
    "### Exemple Complet pour l'Évaluation\n",
    "\n",
    "Voici un exemple complet intégrant les différentes étapes d’évaluation :\n",
    "\n",
    "```python\n",
    "# Évaluation de la perte et de la précision\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
    "print(f'Perte sur l’ensemble de test : {test_loss:.4f}')\n",
    "print(f'Précision sur l’ensemble de test : {test_accuracy * 100:.2f}%')\n",
    "\n",
    "# Prédictions sur l'ensemble de test\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Matrice de confusion et rapport de classification\n",
    "conf_matrix = confusion_matrix(y_true, y_pred_classes)\n",
    "print(\"Matrice de confusion :\")\n",
    "print(conf_matrix)\n",
    "\n",
    "class_report = classification_report(y_true, y_pred_classes)\n",
    "print(\"Rapport de classification :\")\n",
    "print(class_report)\n",
    "\n",
    "# Visualisation des erreurs de classification\n",
    "errors = np.where(y_pred_classes != y_true)[0]\n",
    "plt.figure(figsize=(12, 10))\n",
    "for i, idx in enumerate(errors[:9]):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(x_test[idx].squeeze(), cmap=\"gray\")\n",
    "    plt.title(f\"Vrai : {y_true[idx]}, Prédit : {y_pred_classes[idx]}\")\n",
    "    plt.axis(\"off\")\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "En suivant ces étapes, vous obtenez une évaluation complète des performances de votre modèle CNN, à la fois avec des métriques globales et des analyses détaillées pour chaque classe. Ces informations vous aideront à comprendre où et comment améliorer le modèle si nécessaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d06387c2-9ca5-4ee5-bb69-ccc078f9a049",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A vous de jouer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec590246-ac98-4fe8-8995-17c62efdf6f0",
   "metadata": {},
   "source": [
    "# Exercice\n",
    "\n",
    "Créez et optimisez un modèle de CNN pour prédire les classes d'images en utilisant les données de votre choix parmi ceux d'Image Classification dans les datasets de TensorFlow : https://www.tensorflow.org/datasets/catalog/beans?hl=fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701090fd-7aed-4e5e-a36a-df9ed2793442",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
