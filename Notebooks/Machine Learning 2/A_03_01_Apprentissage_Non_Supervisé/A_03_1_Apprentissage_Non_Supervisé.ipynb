{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44e8663b-aec8-4c1d-994b-b7ce37ef391e",
   "metadata": {},
   "source": [
    "# Introduction à l'Apprentissage Non Supervisé"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597836c8-0dbe-46e2-8fbf-0943cb828025",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "Dans cette séance, nous nous concentrons sur **l’apprentissage non supervisé**, une approche du machine learning qui nous aide à identifier des structures cachées dans les données. Contrairement à l’apprentissage supervisé, qui utilise des données avec labels, l’apprentissage non supervisé s’applique à des données non étiquetées. Cela le rend particulièrement utile pour des tâches de découverte de patterns, comme la segmentation de clients ou l’analyse de comportements.\n",
    "\n",
    "### Objectifs\n",
    "\n",
    "- Découvrir les bases de l’apprentissage non supervisé et ses principaux types de techniques.\n",
    "- Apprendre à regrouper des données similaires grâce aux techniques de clustering.\n",
    "- Utiliser la réduction de dimensionnalité pour simplifier les données et faciliter leur visualisation et interprétation.\n",
    "- Appliquer ces techniques dans un contexte pratique pour extraire des insights exploitables dans des projets business."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188dac02-526b-413d-ad64-976eb3f7d399",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## Introduction à l’Apprentissage Non Supervisé"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858d8123-d59c-4fdd-9fe3-24e061dba31a",
   "metadata": {},
   "source": [
    "### Définition\n",
    "\n",
    "L’apprentissage non supervisé est une approche de machine learning dans laquelle l’algorithme explore et analyse les données sans supervision (c’est-à-dire sans labels ou catégories prédéfinies). L’objectif principal est de découvrir des **patterns cachés** ou des **structures** au sein des données, permettant ainsi de comprendre la complexité de ces données et d’identifier des groupements naturels.\n",
    "\n",
    "### Applications\n",
    "\n",
    "L’apprentissage non supervisé est largement utilisé dans plusieurs domaines, notamment :\n",
    "- **Segmentation client en marketing** : Permet d'identifier des groupes de clients avec des comportements ou des préférences similaires pour des campagnes plus ciblées et efficaces.\n",
    "- **Détection d’anomalies** : Utilisé pour repérer des patterns inhabituels dans les données, ce qui peut signaler des fraudes, des erreurs, ou d’autres anomalies.\n",
    "- **Analyse d'image et de texte** : Sert à regrouper des images ou des documents similaires, simplifiant l’organisation de grandes bases de données multimédia.\n",
    "\n",
    "### Types de Techniques en Apprentissage Non Supervisé\n",
    "\n",
    "1. **Clustering (Segmentation)** : Ces méthodes regroupent les données en sous-ensembles appelés clusters, où les éléments dans un même cluster sont plus similaires entre eux qu’avec les autres groupes. \n",
    "   - **Exemples** : K-means, clustering hiérarchique.\n",
    "\n",
    "2. **Réduction de Dimensionnalité** : Ces techniques simplifient les données en réduisant le nombre de variables tout en préservant l’information essentielle, facilitant ainsi l’analyse et la visualisation.\n",
    "   - **Exemple** : Analyse en Composantes Principales (PCA).\n",
    "\n",
    "\n",
    "Dans la suite de la séance, nous allons explorer chaque technique en détail."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81540187-2766-425f-868b-4292d01cac13",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## Introduction au Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db88126-230b-4b6c-8f6d-b78da0b438cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "Le **clustering** est une technique d'apprentissage non supervisé qui vise à regrouper des données en sous-ensembles appelés **clusters** (ou segments), où les éléments au sein d'un même cluster partagent des similarités plus fortes qu’avec les éléments des autres clusters. L’objectif est de découvrir des **patterns** ou des **groupes naturels** dans les données sans étiquettes prédéfinies. \n",
    "\n",
    "Cette technique est largement utilisée dans des domaines comme la segmentation client, l'analyse de comportements, et les systèmes de recommandation.\n",
    "\n",
    "#### Exemple de Dataset : Segmentation de Films\n",
    "\n",
    "Imaginons un dataset contenant des informations sur des films, décrit par les caractéristiques suivantes :\n",
    "- **Genre** (comédie, action, drame, etc.),\n",
    "- **Durée** (en minutes),\n",
    "- **Score des critiques** (sur 100),\n",
    "- **Popularité** (mesurée par le nombre de vues).\n",
    "\n",
    "Voici un exemple de tableau de données pour illustrer :\n",
    "\n",
    "| Film           | Genre      | Durée (min) | Score Critique | Popularité (vues) |\n",
    "|----------------|------------|-------------|----------------|--------------------|\n",
    "| Film A         | Action     | 120         | 75             | 500,000           |\n",
    "| Film B         | Comédie    | 90          | 85             | 200,000           |\n",
    "| Film C         | Drame      | 150         | 90             | 100,000           |\n",
    "| Film D         | Action     | 110         | 70             | 450,000           |\n",
    "| Film E         | Comédie    | 95          | 80             | 220,000           |\n",
    "| Film F         | Drame      | 160         | 88             | 120,000           |\n",
    "| Film G         | Action     | 130         | 78             | 550,000           |\n",
    "| Film H         | Drame      | 145         | 92             | 90,000            |\n",
    "\n",
    "#### Que fait le Clustering avec ces Données ?\n",
    "\n",
    "En appliquant une technique de clustering, comme **K-means**, à ce dataset, l’algorithme va essayer de **regrouper les films en clusters** en fonction de leurs similarités sur les caractéristiques \"Durée\", \"Score Critique\", et \"Popularité\".\n",
    "\n",
    "Par exemple, après l'application du clustering, on pourrait obtenir trois groupes :\n",
    "- **Cluster 1** : Films d’action populaires de durée moyenne, avec un score critique modéré (ex., Film A, Film D, Film G).\n",
    "- **Cluster 2** : Comédies courtes avec un score critique élevé (ex., Film B, Film E).\n",
    "- **Cluster 3** : Drames longs, moins populaires, mais avec un score critique élevé (ex., Film C, Film F, Film H).\n",
    "\n",
    "Ces clusters pourraient être utilisés pour une plateforme de streaming afin de recommander des films en fonction des préférences de chaque utilisateur, en proposant par exemple des drames longs et bien notés aux amateurs de ce genre, ou des films d’action populaires aux fans de sensations fortes. \n",
    "\n",
    "Ainsi, le clustering permet de structurer les données et d’identifier des segments naturels pour des applications ciblées et personnalisées."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c312ece-ff44-4ce0-b445-21be90e52f43",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## Workflow de l'Apprentissage Non Supervisé"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5afba77-1414-4cf3-a16c-2bb221477003",
   "metadata": {},
   "source": [
    "Pour implémenter un modèle d’apprentissage non supervisé, nous suivons un workflow similaire à celui de l’apprentissage supervisé, avec certaines spécificités. Voici les principales étapes :\n",
    "\n",
    "1. **Extraction des données** : Charger et importer les données nécessaires depuis un fichier ou une base de données.\n",
    "\n",
    "2. **Analyse exploratoire des données (EDA)** : Examiner les variables, analyser les distributions et les relations entre variables, et identifier des patterns ou anomalies. Cette étape est cruciale pour comprendre la structure des données et orienter le choix du modèle.\n",
    "\n",
    "3. **Prétraitement des données** :\n",
    "   - **Nettoyage des données** : Gérer les valeurs manquantes, supprimer ou corriger les valeurs aberrantes, si nécessaire.\n",
    "   - **Normalisation ou standardisation** : Adapter les échelles des variables pour éviter que certaines dominent les autres dans l’analyse (spécialement important pour des algorithmes comme K-means).\n",
    "   - **Encodage des variables catégorielles** : Convertir les variables non numériques en valeurs numériques pour que les algorithmes puissent les traiter.\n",
    "\n",
    "4. **Réduction de la dimensionnalité (si nécessaire)** : Pour des données à haute dimension, appliquer des techniques comme la **PCA** (Analyse en Composantes Principales) peut aider à simplifier l’analyse, réduire le bruit, et faciliter la visualisation. Cette étape est particulièrement utile pour visualiser les résultats du clustering dans un espace réduit (2D ou 3D).\n",
    "\n",
    "5. **Application du modèle de clustering** : Exécuter l’algorithme de clustering (comme K-means ou clustering hiérarchique) pour regrouper les données en clusters significatifs.\n",
    "\n",
    "6. **Interprétation et validation des clusters** :\n",
    "   - **Analyse des clusters** : Examiner les caractéristiques de chaque cluster pour interpréter les groupes obtenus.\n",
    "   - **Évaluation indirecte** : En apprentissage non supervisé, l’évaluation est plus subjective car nous n’avons pas de \"réponses\" (labels) pour comparer les résultats. On utilise donc des **mesures indirectes** comme :\n",
    "     - La **méthode de l’Elbow** ou le **coefficient de silhouette** pour évaluer la cohésion des clusters dans K-means.\n",
    "     - La **visualisation des clusters** (souvent après **réduction de dimension**) pour évaluer la séparation entre groupes.\n",
    "\n",
    "\n",
    "### Remarques\n",
    "\n",
    "- **Itérations et Ajustements** : Il est souvent utile de répéter certaines étapes (par exemple, la normalisation ou le choix du nombre de clusters) pour optimiser les résultats et mieux comprendre les données.\n",
    "- **Documentation et Reporting** : Garder une trace des choix, des visualisations, et des résultats obtenus à chaque étape permet de mieux interpréter les clusters et de fournir un rapport clair pour un contexte business ou d’analyse."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889d5d10-9772-4e57-bc77-e904144bdda8",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## Introduction au Dataset : Mall Customers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a61525-2c06-499b-9106-b01fe16917fb",
   "metadata": {
    "tags": []
   },
   "source": [
    "Pour cette séance, nous allons utiliser le **Mall Customers Dataset**, un ensemble de données fictif souvent employé pour la segmentation client en marketing. Ce dataset contient des informations sur des clients d'un centre commercial, et il est particulièrement adapté pour mettre en pratique des techniques de **clustering** afin d'identifier des segments de clients ayant des profils similaires.\n",
    "\n",
    "#### Description du Dataset\n",
    "\n",
    "Le **Mall Customers Dataset** comporte les variables suivantes :\n",
    "- **CustomerID** : Identifiant unique du client.\n",
    "- **Gender** : Sexe du client (Masculin/Féminin).\n",
    "- **Age** : Âge du client.\n",
    "- **Annual Income (k$)** : Revenu annuel du client, en milliers de dollars.\n",
    "- **Spending Score (1-100)** : Score de dépenses, une évaluation de l’engagement du client dans ses achats (entre 1 et 100). Ce score, basé sur le comportement d'achat, indique le niveau d’activité du client, plus il est élevé, plus le client est considéré comme engagé.\n",
    "\n",
    "#### Objectif du Clustering avec ce Dataset\n",
    "\n",
    "L'objectif de l’analyse par clustering avec ce dataset est de **segmenter les clients** en groupes homogènes en fonction de caractéristiques telles que l’âge, le revenu, et le score de dépenses. Ces segments fourniront des insights utiles pour des stratégies de marketing et permettront d'identifier des groupes de clients aux comportements d'achat distincts.\n",
    "\n",
    "Dans les prochaines étapes, nous allons appliquer différentes méthodes de clustering, telles que **K-means** et le **clustering hiérarchique**, pour analyser ces données et explorer la structure des groupes formés.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924a2636-028f-4dd8-b286-50d5745310cf",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## Extraction des Données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa65c3f-a843-4130-af42-0da51b0e07eb",
   "metadata": {},
   "source": [
    "Dans cette étape, nous allons importer le **Mall Customers Dataset** pour préparer notre analyse de clustering. Assurez-vous d’avoir le fichier du dataset dans votre répertoire de travail ou spécifiez son chemin exact.\n",
    "\n",
    "1. **Téléchargez le Dataset** : Placez le fichier **Mall_Customers.csv** dans le même dossier que votre notebook, ou notez son emplacement exact.\n",
    "\n",
    "2. **Chargez le Dataset** : Importez le fichier **Mall_Customers.csv** dans un DataFrame avec **Pandas**.\n",
    "   - Si le fichier est dans le même dossier que votre notebook, utilisez uniquement le nom du fichier.\n",
    "   - Si le fichier est dans un sous-dossier nommé `data` du même répertoire parent, indiquez le chemin `../data/Mall_Customers.csv`.\n",
    "\n",
    "3. **Vérifiez le Chargement** : Affichez les premières lignes du dataset pour confirmer que l’importation est réussie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1369c8db-df33-4f92-b213-a49df56a079a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insérez le code pour charger des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8af09f-68c2-4b13-87bc-19038675c34e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "---\n",
    "## Exploration des Données (EDA) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbd511c-2c81-4dbb-be91-f5baf08de807",
   "metadata": {},
   "source": [
    "L’objectif de cette étape est de comprendre la structure des données, d’analyser les variables, et d'identifier d'éventuelles anomalies ou patterns dans le **Mall Customers Dataset**. Suivez les instructions et utilisez les zones de code pour réaliser chaque analyse. Des questions sont incluses pour guider votre interprétation des résultats.\n",
    "\n",
    "### 1. Aperçu des Données\n",
    "- **Instructions** : \n",
    "    - Affichez un aperçu des premières lignes du dataset pour en comprendre la structure. \n",
    "    - Utilisez `.head()` pour afficher les premières lignes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06eabc24-3920-45f1-987c-d57e26ff0508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insérez le code ici pour afficher un aperçu du dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145e0bb1-bdaa-485c-916a-7f0c386d0048",
   "metadata": {},
   "source": [
    "> **Question** : Quelles sont les différentes variables présentes dans le dataset ? Observez-vous des types de données inattendus ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9ef5a8-4219-4c41-b7ba-a02b6ebfd92d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2. Dimensions et Types de Données\n",
    "- **Instructions** : \n",
    "    - Vérifiez la taille du dataset (nombre de lignes et de colonnes) ainsi que le type de chaque colonne. \n",
    "    - Utilisez `.shape` pour obtenir les dimensions et `.info()` pour les types de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b0f69e8-0b3c-4e2b-8c57-cfe8923bc58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insérez le code ici pour afficher la taille et les types de données du dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65de2a05-68cb-4c1e-aed3-2666cd8d24f7",
   "metadata": {},
   "source": [
    "> **Question** : Combien y a-t-il de clients (lignes) et de variables (colonnes) dans ce dataset ? Les types de données sont-ils conformes aux attentes ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c693348d-cd42-4d76-a053-e59aac883939",
   "metadata": {},
   "source": [
    "### 3. Résumé Statistique\n",
    "- **Instructions** : \n",
    "    - Obtenez un résumé statistique des variables numériques pour analyser les valeurs minimales, maximales, moyennes, etc.\n",
    "    - Utilisez `.describe()` pour afficher les statistiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eef58541-0339-485d-955c-46dbe7ec4c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insérez le code ici pour afficher les statistiques descriptives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5b46e3-d981-4558-a6c5-3524f34c45c3",
   "metadata": {},
   "source": [
    "> **Question** : Quelle est la distribution des âges, des revenus annuels et des scores de dépenses ? Y a-t-il des valeurs extrêmes (très hautes ou très basses) ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31485e7-93e9-4464-bb7f-3fbda3c4f385",
   "metadata": {},
   "source": [
    "### 4. Vérification des Valeurs Manquantes\n",
    "- **Instructions** : \n",
    "    - Vérifiez s’il y a des valeurs manquantes dans le dataset.\n",
    "    - Utilisez `.isnull().sum()` pour compter les valeurs manquantes par colonne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e7863db-c383-4257-b31a-d665dc087370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insérez le code ici pour vérifier les valeurs manquantes dans chaque colonne"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cf6b4c-4cef-40be-a014-1bd4b3a3744a",
   "metadata": {},
   "source": [
    "> **Question** : Y a-t-il des valeurs manquantes ? Si oui, dans quelles colonnes, et comment cela pourrait-il affecter notre analyse ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0aee1c9-ffaf-41e9-a435-69bd15f9a77b",
   "metadata": {},
   "source": [
    "### 5. Exploration des Points Abérants\n",
    "- **Instructions** : \n",
    "    - Identifiez les points aberrants dans les variables principales (âge, revenu annuel, score de dépenses) en utilisant des graphiques de boîte (boxplots) pour détecter des valeurs extrêmes.\n",
    "    - Utilisez des bibliothèques comme **Matplotlib** ou **Seaborn** pour créer des boxplots des variables principales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8312c7cd-3948-4f56-984c-76eb8a8fedc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insérez le code ici pour visualiser les points aberrants dans les variables clés"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70eacf7-44c6-4492-a65a-94b7cf18caa2",
   "metadata": {},
   "source": [
    "> **Question** : Observez-vous des valeurs aberrantes dans les variables principales ? Comment ces valeurs extrêmes pourraient-elles influencer le clustering ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1079e026-27db-4245-b340-4a0fffd388d2",
   "metadata": {},
   "source": [
    "### 6. Distribution des Variables Clés\n",
    "- **Instructions** : \n",
    "    - Visualisez la distribution des variables clés (âge, revenu annuel, et score de dépenses) à l’aide d’histogrammes pour mieux comprendre les caractéristiques des clients.\n",
    "    - Utilisez des bibliothèques comme **Matplotlib** ou **Seaborn** pour créer des histogrammes des variables principales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f0eabaf-467b-483c-960f-25faafd787d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insérez le code ici pour visualiser la distribution des variables principales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b116f79d-6fb7-4a5c-82bc-80c7d35af0af",
   "metadata": {},
   "source": [
    "> **Question** : Comment les clients se répartissent-ils en fonction de leur âge, revenu et score de dépenses ? Observez-vous des tendances ou des patterns particuliers ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a2e4a0-12ce-4b9e-94a5-9a62f414df09",
   "metadata": {},
   "source": [
    "### 7. Analyse de la Variable Catégorielle : Genre\n",
    "- **Instructions** : Étudiez la répartition des genres pour voir si le dataset contient une proportion équilibrée de clients masculins et féminins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4fcd200-f65e-486b-9818-15d102667bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insérez le code ici pour visualiser la répartition de la variable \"Gender\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e9f7f2-cc04-43d4-bdfb-83e4226e5e41",
   "metadata": {},
   "source": [
    "> **Question** : La répartition entre genres est-elle équilibrée ? Comment cela pourrait-il influencer la segmentation ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72baa5a8-2c77-4839-abbb-52e681de0733",
   "metadata": {},
   "source": [
    "### 8. Analyse des Corrélations\n",
    "- **Instructions** : \n",
    "    - Vérifiez s’il existe des corrélations entre les variables numériques. Une corrélation forte pourrait indiquer une relation entre certaines caractéristiques des clients.\n",
    "    - Utilisez `.corr()` pour calculer la matrice de corrélation, et visualisez-la avec une **heatmap** de Seaborn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "332cdcde-483d-4a0a-852a-62e7962c47b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insérez le code ici pour calculer et visualiser la matrice de corrélation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36623ccd-0ce6-4b03-aeb4-aa96a69adb33",
   "metadata": {},
   "source": [
    "> **Question** : Y a-t-il des corrélations significatives entre les variables ? Comment cela pourrait-il influencer le clustering ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa5d5ec-6b66-4c55-90d6-9d5f363a8abd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "---\n",
    "## Prétraitement des Données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1999b303-1ef8-496a-a228-f600adb3be01",
   "metadata": {},
   "source": [
    "Le prétraitement des données est une étape cruciale avant d’appliquer des algorithmes de clustering, comme **K-means** et le **clustering hiérarchique**. Les deux techniques nécessitent des données propres et bien préparées pour produire des clusters significatifs. Voici les étapes de prétraitement recommandées pour ce dataset et ces deux méthodes.\n",
    "\n",
    "\n",
    "### 1. Sélection des Variables\n",
    "\n",
    "- **Instructions** : Choisissez les variables les plus pertinentes pour l’analyse de clustering. Pour le **Mall Customers Dataset**, les variables numériques comme `Age`, `Annual Income (k$)`, et `Spending Score (1-100)` sont particulièrement adaptées pour segmenter les clients. La variable `Gender`, qui est catégorielle, peut être incluse si vous pensez qu’elle pourrait enrichir les segments après encodage.\n",
    "\n",
    "> **Question** : Quelles variables semblent les plus appropriées pour la segmentation des clients et pourquoi ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8141531-2db0-4adc-b0ba-561604e6d598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insérez ici le code pour selectionner les variables les plus pertinantes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ef2c1b-3c3b-4ee0-8fb6-225322a68260",
   "metadata": {},
   "source": [
    "### 2. Encodage des Variables Catégorielles (si nécessaire)\n",
    "\n",
    "- **Instructions** : Si vous incluez des variables catégorielles comme `Gender`, transformez-les en valeurs numériques. Le **K-means** et le **clustering hiérarchique** nécessitent des données numériques pour calculer les distances entre les points.\n",
    "   - Utilisez un **encodage binaire** (0, 1) pour la variable `Gender` ou d'autres techniques d'encodage adaptées aux valeurs catégorielles si vous ajoutez d'autres données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9400f403-27c5-4253-9210-98fa987613b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insérez ici le code pour encoder les variables catégorielles, si nécessaire"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3649bd-ce50-4e02-bb7b-fb75dd1a782a",
   "metadata": {},
   "source": [
    "### 3. Standardisation des Variables\n",
    "\n",
    "Les algorithmes de clustering, et en particulier **K-means**, sont sensibles aux échelles des variables. Si les variables ont des unités différentes (par exemple, âge en années, revenu en milliers de dollars, score de dépenses sur 1 à 100), cela pourrait biaiser les clusters. La **standardisation** permet de mettre toutes les variables sur la même échelle.\n",
    "\n",
    "- **Instructions** : Standardisez les variables sélectionnées en les transformant pour qu’elles aient une moyenne de 0 et un écart-type de 1 (z-score standardisation).\n",
    "   - Utilisez la **standardisation** pour le clustering K-means et le clustering hiérarchique pour garantir que toutes les variables contribuent de manière égale aux clusters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22b6721f-6c96-4b29-98a3-2433741c0899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insérez ici le code pour standardiser les variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ca18b9-d4ed-478b-9bbd-efa7c95b4b6b",
   "metadata": {},
   "source": [
    "### 4. Détection et Gestion des Valeurs Aberrantes\n",
    "\n",
    "- **Instructions** : Les valeurs aberrantes peuvent fausser les résultats du clustering, surtout avec K-means. Identifiez et, si nécessaire, traitez les valeurs extrêmes détectées lors de l'EDA.\n",
    "   - Vous pouvez filtrer les valeurs aberrantes si elles risquent d'influencer fortement les clusters, ou simplement les garder en les notant pour interpréter les résultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e52db713-5625-4244-a93b-981e6723e0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insérez ici le code pour traiter ou marquer les valeurs aberrantes, si nécessaire"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb385d7a-98e5-4d99-b44c-4d55aae0779e",
   "metadata": {},
   "source": [
    "> **Question** : Quelles valeurs extrêmes identifiées pourraient affecter la formation des clusters ? Est-il nécessaire de les supprimer ou de les conserver pour l’interprétation des résultats ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095ca4a8-09ec-4ace-bc82-4610fe680a84",
   "metadata": {},
   "source": [
    "### 5. Vérification du Dataset Final\n",
    "\n",
    "- **Instructions** : Vérifiez que toutes les étapes de prétraitement sont bien effectuées et que les données sont prêtes pour le clustering.\n",
    "   - Affichez les premières lignes du dataset final pour vous assurer que toutes les variables sont numériques et que les échelles ont été harmonisées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12def804-007e-4fde-a078-3b9c4cf21b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insérez ici le code pour afficher un aperçu du dataset final après prétraitement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0862431a-6624-4e0d-922c-459626a166de",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "---\n",
    "## K-means Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f044ee36-ee58-4e90-abb1-171d9c5964a2",
   "metadata": {},
   "source": [
    "Dans cette section, nous allons introduire théoriquement l'algorithme K-means, puis l'appliquer au **Mall Customers Dataset** pour segmenter les clients en fonction de leurs caractéristiques. \n",
    "\n",
    "\n",
    "### Introduction à K-means\n",
    "\n",
    "**K-means** est un algorithme de clustering non supervisé qui regroupe les données en **K clusters** distincts en fonction de leur similarité. L'objectif est de minimiser la distance entre les points d'un cluster et le centre de ce cluster, appelé le **centroïde**. Les clusters obtenus permettent de regrouper les données en segments ayant des caractéristiques similaires.\n",
    "\n",
    "<img src=\"kmeans.png\" alt=\"kmeans.png\" width=\"400\" height=\"300\">\n",
    "\n",
    "\n",
    "### Fonctionnement de l'algorithme K-means\n",
    "\n",
    "1. **Initialisation** : Choisir un nombre de clusters `K` et initialiser `K` centroïdes aléatoires.\n",
    "2. **Assignation** : Assigner chaque point de données au centroïde le plus proche, formant ainsi des clusters.\n",
    "3. **Mise à jour** : Recalculer les positions des centroïdes en prenant la moyenne de tous les points assignés à chaque cluster.\n",
    "4. **Itération** : Répéter les étapes d'assignation et de mise à jour jusqu'à ce que les centroïdes ne bougent plus (convergence) ou qu'un nombre maximal d'itérations soit atteint.\n",
    "\n",
    "![kmeans-algo-steps.png](kmeans-algo-steps.png) \n",
    "\n",
    "### Choix du nombre de clusters (K)\n",
    "\n",
    "Le choix du nombre de clusters `K` est crucial. On peut utiliser plusieurs méthodes pour déterminer une valeur optimale de `K` :\n",
    "- **Méthode de l’Elbow** : Cette méthode consiste à tracer la somme des distances des points au centroïde le plus proche pour différents nombres de clusters `K`. Le \"coude\" de la courbe indique un bon choix pour `K`.\n",
    "\n",
    "![elbow-method.png](elbow-method.png)\n",
    "\n",
    "- **Coefficient de silhouette** : Mesure la cohésion et la séparation des clusters. Un coefficient élevé indique des clusters bien séparés et compacts.\n",
    "\n",
    "![silouette-intergroupeinertia.png](silouette-intergroupeinertia.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2d8bf3-9b0c-45de-8689-9ad0eb363275",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## Application de K-means sur le Mall Customers Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befd7dd4-f323-4066-8c6f-62b82558c50f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Étape 1 : Sélection du Nombre Optimal de Clusters (K)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0ddc47-209b-4740-b829-06c58d8ef3c6",
   "metadata": {},
   "source": [
    "**Instructions** : Utilisez la méthode de l’Elbow pour déterminer le nombre optimal de clusters `K` dans le **Mall Customers Dataset**.\n",
    "\n",
    "**Indications** :\n",
    "\n",
    "1. **Préparation du Modèle K-means** :\n",
    "   - **Importez** la classe `KMeans` depuis `sklearn.cluster`.\n",
    "   - Utilisez une **boucle** pour tester plusieurs valeurs de `K` (par exemple, de 1 à 10).\n",
    "\n",
    "2. **Calcul de l'inertie** :\n",
    "   - Dans chaque itération de la boucle, créez un modèle K-means avec un nombre de clusters `K` en utilisant `KMeans(n_clusters=K, random_state=0)`.\n",
    "   - Appelez la méthode `.fit()` sur les données prétraitées (comme pour un modèle supervisé), afin que K-means ajuste les clusters en fonction des données.\n",
    "   - Après avoir ajusté le modèle, récupérez l'**inertie** (somme des distances des points au centroïde le plus proche) en utilisant l'attribut `.inertia_`.\n",
    "   - Stockez cette valeur d'inertie dans une liste pour chaque valeur de `K` testée.\n",
    "\n",
    "3. **Tracé de la courbe de l’Elbow** :\n",
    "   - Une fois la boucle terminée, tracez la courbe de l'inertie en fonction des valeurs de `K`.\n",
    "   - Cherchez le \"coude\" de la courbe, où la réduction de l'inertie commence à ralentir, ce qui indique un bon choix pour `K`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57e46662-3f1b-4949-af88-aff98b13a903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insérez ici le code pour calculer l'inertie et tracer la courbe de l'Elbow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ab8044-6753-480e-8bd2-62ba16606eb1",
   "metadata": {},
   "source": [
    "> **Question** : Où se situe le \"coude\" de la courbe ? Quel serait un choix raisonnable pour le nombre de clusters `K` ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e81208a-d695-4898-bb11-66d30a25687d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Étape 2 : Appliquer K-means avec le Nombre Optimal de Clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9290204-cfec-4a0e-a253-3fb9dd4920ad",
   "metadata": {},
   "source": [
    "**Instructions** : Appliquez l'algorithme K-means sur le **Mall Customers Dataset** en utilisant le nombre optimal de clusters `K` déterminé à l’étape précédente.\n",
    "\n",
    "**Indications** :\n",
    "\n",
    "1. **Initialiser le Modèle** :\n",
    "   - Importez `KMeans` depuis `sklearn.cluster` si ce n'est pas déjà fait.\n",
    "   - Créez une instance de `KMeans` avec le nombre de clusters optimal `K` trouvé lors de l’étape précédente. Assurez-vous de définir un `random_state` (par exemple, `random_state=0`) pour obtenir des résultats reproductibles.\n",
    "   - Exemple de configuration : `KMeans(n_clusters=K, random_state=0)`.\n",
    "\n",
    "2. **Ajuster le Modèle (fit)** :\n",
    "   - Utilisez la méthode `.fit()` sur le dataset prétraité pour ajuster K-means aux données et calculer les clusters.\n",
    "   - Cela permet à l'algorithme de calculer les centroïdes et d'assigner chaque point de données au cluster le plus proche.\n",
    "\n",
    "3. **Récupérer les Labels de Cluster** :\n",
    "   - Une fois le modèle ajusté, récupérez les labels de cluster (attribution de chaque client à un cluster) en utilisant l’attribut `.labels_`.\n",
    "   - Ajoutez ces labels comme une nouvelle colonne dans le DataFrame initial, par exemple en utilisant le nom de colonne `\"Cluster\"` pour pouvoir analyser les segments créés.\n",
    "\n",
    "4. **Vérification des Clusters** :\n",
    "   - Affichez les premières lignes du DataFrame pour vérifier que les clients sont bien assignés à un cluster.\n",
    "   - Observez la répartition des clusters pour voir s'ils sont équilibrés et si des regroupements naturels apparaissent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c41ad40a-35d5-448a-836c-52ffb62dafc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insérez ici le code pour appliquer K-means avec le nombre optimal de clusters et ajouter les labels de cluster au DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7c4474-1971-436b-ba10-e748de7b77a8",
   "metadata": {},
   "source": [
    "> **Question** : Les clusters semblent-ils équilibrés ? Observez-vous des regroupements cohérents en fonction de l’âge, du revenu ou du score de dépenses ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a97a1b3-fc48-4b50-bdd2-cb096f4f75fd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Étape 3 : Visualisation des Clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f275e9-8043-4c18-9db1-41bc2eb00da6",
   "metadata": {},
   "source": [
    "1. **Instructions** : Visualisez les clusters formés pour observer la segmentation des clients et comprendre les patterns dans les données.\n",
    "2. **Indications** :\n",
    "   - Utilisez un **nuage de points** pour représenter les clients en fonction de deux variables à la fois, par exemple, `Annual Income (k$)` et `Spending Score (1-100)`.\n",
    "   - Assignez une couleur à chaque cluster pour distinguer les groupes.\n",
    "   - Testez différentes combinaisons de variables (par exemple, `Age` et `Spending Score`, ou `Age` et `Annual Income` ou par rapport au `Gender`) pour explorer les regroupements sous plusieurs angles et obtenir des insights sur les segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae0b5ec1-3c1f-41bc-9ef5-4856eff23dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insérez ici le code pour visualiser les clusters en utilisant différentes combinaisons de variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b41282-11bb-4d84-934e-703d637285ce",
   "metadata": {},
   "source": [
    "> **Question** : Quels patterns observez-vous dans les clusters en fonction des différentes combinaisons de variables ? Certains clusters représentent-ils des segments spécifiques, comme des clients jeunes à haut revenu ou des clients âgés avec un faible score de dépenses ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d428100d-3552-4aeb-8df0-4305897bf425",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Étape 4 : Interprétation des Clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c0fd35-b45d-402a-a706-5ccb939374ce",
   "metadata": {},
   "source": [
    "1. **Instructions** : Analysez les caractéristiques de chaque cluster en tenant compte des conclusions de l’étape de visualisation. Cela vous permettra de confirmer ou d'affiner les profils de chaque groupe de clients.\n",
    "\n",
    "2. **Indications** :\n",
    "   - **Calculez les moyennes** des principales variables (`Age`, `Annual Income (k$)`, `Spending Score (1-100)`) pour chaque cluster afin de décrire les attributs moyens des clients de chaque groupe.\n",
    "   - **Interprétez les segments** en observant les différences entre les clusters, en particulier en fonction de :\n",
    "     - **Revenu annuel** : Identifiez des segments comme les **clients à faible revenu** ou les **clients à revenu élevé**.\n",
    "     - **Score de dépenses** : Distinguez les clients très engagés (score élevé) des clients moins actifs.\n",
    "     - **Âge** : Repérez les segments par tranches d’âge, tels que **jeunes adultes** ou **clients plus âgés**.\n",
    "   - **Établissez des profils de clients** en combinant ces caractéristiques pour chaque cluster et en prenant en considération les observations faites lors de l’étape de visualisation. Par exemple :\n",
    "     - Un cluster avec une moyenne élevée de **revenu annuel** et de **score de dépenses** pourrait représenter des **clients fidèles et fortunés**, comme cela peut avoir été observé visuellement.\n",
    "     - Un cluster avec un faible **revenu** et un **score de dépenses faible** pourrait correspondre aux **clients occasionnels** ou **clients à faible pouvoir d'achat**, comme vu dans la distribution.\n",
    "\n",
    "3. **Exemple de Description de Clusters** :\n",
    "   - **Cluster 1** : Clients jeunes, avec un revenu annuel moyen mais un score de dépenses élevé — **Clients engagés et potentiellement influençables pour des offres promotionnelles**.\n",
    "   - **Cluster 2** : Clients plus âgés, revenu élevé, score de dépenses modéré — **Clients fidèles et stables, avec un potentiel pour les produits haut de gamme**.\n",
    "   - **Cluster 3** : Revenu faible, score de dépenses faible, tout âge — **Clients occasionnels ou à faible pouvoir d'achat, potentiellement sensibles aux promotions**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "26e383e2-d23a-48a2-8c08-ed7cd685a226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insérez ici le code pour calculer les moyennes par cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8175915-67b0-4453-8c7f-c76e7ab4ac6e",
   "metadata": {},
   "source": [
    "> **Question** : Quels sont les profils des clients dans chaque cluster ? Comment les observations de l’étape de visualisation renforcent-elles ou affinent-elles ces segments ? Comment ces segments pourraient-ils être utilisés pour des actions marketing ciblées (par exemple, offres promotionnelles, produits premium, fidélisation) ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b02990-d115-4370-ae19-c762a3ba2245",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "---\n",
    "## Clustering Hiérarchique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b42cca-544e-41e3-a859-1d2f20c94bcc",
   "metadata": {
    "tags": []
   },
   "source": [
    "Dans cette section, nous allons introduire le clustering hiérarchique de manière théorique, puis l'appliquer au **Mall Customers Dataset** pour segmenter les clients en groupes. Le clustering hiérarchique est particulièrement utile lorsque nous voulons explorer les relations entre les données sous forme de niveaux ou de sous-groupes.\n",
    "\n",
    "\n",
    "### Introduction au Clustering Hiérarchique\n",
    "\n",
    "Le **clustering hiérarchique** est une technique de clustering non supervisée qui construit une hiérarchie de clusters en organisant les données sous forme d’un arbre, ou **dendrogramme**. Cet algorithme n’a pas besoin de spécifier un nombre de clusters au départ ; il crée plutôt une structure arborescente, permettant de diviser les clusters à différents niveaux selon le niveau de similarité souhaité.\n",
    "\n",
    "![hierarchical-clustering.png](hierarchical-clustering.png)\n",
    "\n",
    "### Types de Clustering Hiérarchique\n",
    "\n",
    "1. **Clustering Agglomératif (Bottom-Up)** : Part de chaque point comme un cluster individuel, puis fusionne successivement les clusters les plus proches jusqu’à former un seul cluster englobant.\n",
    "2. **Clustering Divisif (Top-Down)** : Commence avec un seul cluster englobant tous les points et divise successivement les clusters jusqu’à ce que chaque point soit isolé (moins couramment utilisé).\n",
    "\n",
    "Nous utiliserons ici la méthode **agglomérative**, la plus populaire, qui permet de visualiser les regroupements progressifs dans un dendrogramme.\n",
    "\n",
    "### Mesures de Distance et Critères de Liaison\n",
    "\n",
    "- **Distance** : Les distances entre points peuvent être mesurées de différentes manières (euclidienne, Manhattan, etc.), mais la distance euclidienne est la plus courante pour le clustering.\n",
    "- **Critère de Liaison** : Définit la manière dont les distances sont calculées entre clusters. Les critères principaux sont :\n",
    "  - **Lien simple (single linkage)** : Distance minimale entre deux clusters.\n",
    "  - **Lien complet (complete linkage)** : Distance maximale entre deux clusters.\n",
    "  - **Lien moyen (average linkage)** : Moyenne des distances entre les points des deux clusters.\n",
    "  - **Lien Ward** : Minimise la variance entre les clusters et est souvent recommandé pour obtenir des clusters équilibrés.\n",
    "\n",
    "<img src=\"hiearchical-clustering-linkages.png\" width=\"800\" height=\"400\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39fe859-4ebb-4921-84f7-3648162a02d0",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## Application du Clustering Hiérarchique sur le Mall Customers Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cac65f-ee60-4ede-ae6e-1d8845d362c1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Étape 1 : Calcul des Distances et Construction du Dendrogramme"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d02516-74d9-4843-83e1-91ce8a16cd22",
   "metadata": {},
   "source": [
    "1. **Instructions** : Créez un dendrogramme pour visualiser la structure des clusters formés par le clustering hiérarchique. Ce graphique vous permettra de déterminer le nombre optimal de clusters en identifiant un seuil de coupe dans l’arbre.\n",
    "\n",
    "2. **Indications** :\n",
    "   - Importez `dendrogram` et `linkage` depuis `scipy.cluster.hierarchy`.\n",
    "   - Utilisez la fonction `linkage` pour calculer les distances entre les points et construire le dendrogramme. Spécifiez le **critère de liaison** (par exemple, `method='ward'` pour un clustering équilibré).\n",
    "   - Utilisez la fonction `dendrogram` pour tracer l’arbre de clusters. Observez les niveaux de coupe pour identifier un nombre raisonnable de clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b0c02e1-c209-4711-b324-8a7675d72a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insérez ici le code pour créer le dendrogramme"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d137313a-93df-4c1c-ac75-4024140e321d",
   "metadata": {},
   "source": [
    "> **Question** : Où pouvez-vous couper le dendrogramme pour obtenir des clusters distincts ? Quel nombre de clusters semble optimal en fonction de la structure de l’arbre ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a6ed0c-61da-4861-8bb2-2ff3bc1f94d3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Étape 2 : Appliquer le Clustering Hiérarchique avec un Nombre de Clusters Spécifique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c692c10f-1adc-4329-931c-7957fee99d79",
   "metadata": {},
   "source": [
    "1. **Instructions** : Appliquez le clustering hiérarchique en utilisant le nombre de clusters que vous avez identifié dans le dendrogramme, et assignez chaque client à un cluster.\n",
    "\n",
    "2. **Indications** :\n",
    "   - Importez `AgglomerativeClustering` depuis `sklearn.cluster`.\n",
    "   - Configurez le modèle avec le nombre de clusters que vous avez choisi et utilisez le même critère de liaison (ex., `linkage='ward'`).\n",
    "   - Appliquez le modèle en appelant `.fit_predict()` sur les données prétraitées pour obtenir les labels de clusters de chaque client.\n",
    "   - Ajoutez ces labels en tant que nouvelle colonne dans le DataFrame initiale pour faciliter l’analyse.\n",
    "\n",
    "> **Note** : `.fit_predict()` est une méthode pratique qui combine `.fit()` et l’extraction des labels avec `.labels_`. Elle entraîne le modèle et retourne directement les labels de clusters. Vous pouvez également utiliser `.fit()` suivi de `.labels_` pour obtenir les labels de clusters séparément. **Alternativement**, utiliser `.predict()` après `.fit()` est possible, mais dans ce cas, `.predict()` retourne uniquement les clusters déjà formés (comme en apprentissage supervisé), ce qui est rarement utilisé en clustering hiérarchique.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0d499a98-05f9-4788-ad4f-02366ee299d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insérez ici le code pour appliquer le clustering hiérarchique et ajouter les labels de clusters au DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1747e7a-fd68-43b3-8aa5-09989c5ee8bc",
   "metadata": {},
   "source": [
    "> **Question** : Comment les clusters se comparent-ils à ceux formés par K-means ? Observez-vous des regroupements similaires ou des différences dans les segments créés ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfae884-5a39-43b6-98ab-b9ba14758d5f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Étape 3 : Visualisation des Clusters Hiérarchiques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861f39de-8b98-4129-b4e8-ad29fad8ed98",
   "metadata": {},
   "source": [
    "1. **Instructions** : Visualisez les clusters hiérarchiques en utilisant différentes combinaisons de variables pour observer les segments de clients.\n",
    "   \n",
    "2. **Indications** :\n",
    "   - Utilisez un **nuage de points** pour représenter les clients en fonction de deux variables (ex., `Annual Income (k$)` et `Spending Score (1-100)`), en colorant les points selon les labels de clusters obtenus avec le clustering hiérarchique.\n",
    "   - Testez plusieurs combinaisons de variables (`Age` et `Spending Score`, `Age` et `Annual Income`, etc.) pour identifier des regroupements spécifiques et obtenir des insights supplémentaires sur les segments créés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "70b52bc0-5c67-4e9a-93de-a32bafcf8247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insérez ici le code pour visualiser les clusters hiérarchiques en utilisant différentes combinaisons de variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f969fa-2d86-46e7-8c6c-5f04ddfedb19",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Étape 4 : Interprétation des Clusters Hiérarchiques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8577a101-d55d-4616-bcd0-2de3ec1db43f",
   "metadata": {},
   "source": [
    "> **Question** : Quels regroupements spécifiques observez-vous dans les clusters hiérarchiques par rapport à K-means ? Les deux approches montrent-elles des patterns similaires ou complémentaires ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f88a7f1-52d2-4bf3-b61d-d664b63c8768",
   "metadata": {},
   "source": [
    "1. **Instructions** : Analysez les caractéristiques des clusters hiérarchiques et comparez-les aux clusters formés par K-means pour en dégager des segments de clients distincts.\n",
    "\n",
    "2. **Indications** :\n",
    "   - **Calculez les moyennes** de chaque variable (`Age`, `Annual Income (k$)`, `Spending Score (1-100)`) pour chaque cluster hiérarchique, comme dans l’interprétation de K-means, afin de mieux comprendre le profil des clients.\n",
    "   - **Décrivez les segments** en fonction de leurs caractéristiques, par exemple :\n",
    "     - Un cluster de **clients à haut revenu et score de dépenses élevé** peut représenter des **clients fidèles et fortunés**.\n",
    "     - Un cluster de **clients à faible revenu et faible score de dépenses** pourrait indiquer des **clients occasionnels ou sensibles aux promotions**.\n",
    "   - **Comparez les clusters avec ceux de K-means** pour voir si des similarités ou des différences dans les regroupements se manifestent, ce qui pourrait fournir des insights supplémentaires sur les segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ad0d38f2-45cf-4fdc-8ff6-a471653dea1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insérez ici le code pour calculer les moyennes par cluster hiérarchique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6329c5c-e4fa-412d-b87c-8597c3bc007c",
   "metadata": {},
   "source": [
    "> **Question** : Comment les clusters hiérarchiques diffèrent-ils de ceux formés par K-means ? Quels segments sont similaires, et quels nouveaux insights apportent les clusters hiérarchiques ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c06e446-73ba-463a-94de-9f8b9b8a24e8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "---\n",
    "## Comparaison des Résultats entre K-means et Clustering Hiérarchique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad00312-8a71-4425-a038-b592a1b451a5",
   "metadata": {
    "tags": []
   },
   "source": [
    "1. **Instructions** : Comparez les clusters formés par les deux méthodes pour identifier des similarités et des différences dans les segments de clients obtenus.\n",
    "2. **Indications** :\n",
    "   - **Comparer les tailles des clusters** : Observez si les clusters obtenus avec les deux méthodes ont des tailles similaires ou différentes.\n",
    "   - **Comparer les caractéristiques moyennes** : Calculez les moyennes de chaque variable par cluster dans les deux méthodes et comparez-les pour chaque segment.\n",
    "   - **Visualiser les clusters côte à côte** : Utilisez des graphiques pour visualiser les clusters de K-means et du clustering hiérarchique sur les mêmes combinaisons de variables (par ex., `Annual Income` et `Spending Score`) afin de repérer des regroupements similaires ou des distinctions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a42a1673-569d-48a5-b25e-d831030c8803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insérez ici le code pour comparer les caractéristiques moyennes des clusters de K-means et du clustering hiérarchique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcac1f7a-b960-457f-b5fc-d37e1ec668db",
   "metadata": {},
   "source": [
    "> **Questions** :\n",
    "   >- Quels clusters se ressemblent dans les deux méthodes ? Quels sont les segments uniques créés par chacune des méthodes ?\n",
    "   >- Quel algorithme semble le mieux adapté aux besoins de segmentation des clients du **Mall Customers Dataset** ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be21d14c-6713-4860-a0d2-7a160a84dbec",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "---\n",
    "## Réduction de Dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9bcd6f-0778-4909-9595-8829933269aa",
   "metadata": {},
   "source": [
    "La **réduction de dimension** est une technique qui permet de simplifier un dataset en réduisant le nombre de variables, tout en conservant un maximum d’information. Cela facilite l'interprétation des données et, dans ce cas, la visualisation des clusters formés par les algorithmes de K-means et de clustering hiérarchique.\n",
    "\n",
    "### Introduction Théorique à la Réduction de Dimension\n",
    "\n",
    "L’**Analyse en Composantes Principales (PCA)** est l'une des méthodes de réduction de dimension les plus courantes pour les données numériques. Elle transforme les variables d’origine en de nouvelles variables appelées **composantes principales**, en maximisant la variance expliquée par chaque composante. Cette technique est particulièrement utile pour réduire la complexité de jeux de données comportant des variables corrélées.\n",
    "\n",
    "#### Note sur les Données Catégorielles\n",
    "> **Note** : La PCA est adaptée uniquement aux **données numériques continues**. Elle ne fonctionne pas directement avec des données catégorielles, car celles-ci n'ont pas de variance ou de covariance calculables de manière classique. Si votre dataset contient des variables catégorielles (comme `Gender` dans le **Mall Customers Dataset**), sélectionnez uniquement les variables numériques pour la PCA. Pour les données catégorielles, des méthodes alternatives comme l’**Analyse des Correspondances Multiples (ACM)** sont recommandées pour réduire la dimension.\n",
    "\n",
    "> **Dans cette section** : Nous allons utiliser la PCA pour visualiser les clusters formés par K-means et le clustering hiérarchique en projetant les données dans un espace 2D. Cette réduction de dimension nous permettra de mieux comprendre la séparation des groupes de clients.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3cb22c-0704-4db4-9f9d-77efbe566256",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Application de la Réduction de Dimension pour Visualiser les Clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2533684-6c41-43b6-b16e-cbc79c1dbf75",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Étape 1 : Sélection des Données Numériques et Application de la PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d462977d-533d-40e9-a889-36f8bb5b2d18",
   "metadata": {},
   "source": [
    "1. **Instructions** : Avant d’appliquer la PCA, utilisez les **variables numériques standardisées** (`Age`, `Annual Income (k$)`, et `Spending Score (1-100)`) du dataset. La standardisation assure que chaque variable est sur une échelle similaire, ce qui est essentiel pour la PCA.\n",
    "\n",
    "2. **Indications** :\n",
    "   - **Sélection des données numériques standardisées** : Filtrez le DataFrame pour ne conserver que les colonnes numériques standardisées. Ces données devraient déjà être disponibles dans votre DataFrame suite aux étapes de prétraitement.\n",
    "   - **Configurer et ajuster la PCA** :\n",
    "     - Importez la classe `PCA` depuis `sklearn.decomposition`.\n",
    "     - Créez une instance de `PCA` avec `n_components=2` pour obtenir les deux premières composantes principales.\n",
    "     - Appliquez `.fit()` sur les données standardisées pour ajuster la PCA.\n",
    "   - **Transformer les données** :\n",
    "     - Utilisez la méthode `.transform()` sur les mêmes données pour obtenir un dataset réduit à 2 dimensions, basé sur les deux composantes principales.\n",
    "     - Les données transformées représenteront chaque observation dans un espace 2D, facilitant la visualisation des clusters.\n",
    "\n",
    "3. **Récupérer la proportion de variance expliquée** :\n",
    "   - Après avoir ajusté la PCA avec `.fit()`, utilisez l’attribut `.explained_variance_ratio_` pour obtenir la proportion de variance capturée par chaque composante principale.\n",
    "   - Additionnez les valeurs des deux premières composantes pour connaître la proportion totale de variance expliquée dans l’espace 2D.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e8167148-0b02-4a3a-b87d-4eda051b8c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insérez ici le code pour appliquer la PCA aux données standardisées et transformer les données en 2 dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97daa723-cc95-47e3-9802-68f1ffcf1ae2",
   "metadata": {},
   "source": [
    "> **Question** : Quelle proportion de variance est capturée par ces deux premières composantes ? Cette proportion est-elle suffisante pour bien représenter les données en 2D ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d12c29-e964-4f21-b25d-0b3b92b361e5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Étape 2 : Visualiser les Clusters en 2D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9189e5ad-351f-457d-950f-38cfe7af0307",
   "metadata": {},
   "source": [
    "**Objectif** : Cette étape vise à **visualiser les clusters obtenus** par K-means et le clustering hiérarchique dans un espace 2D, en utilisant les deux premières composantes principales de la PCA. Cette réduction de dimension permet d'observer la séparation des clusters de manière simplifiée, facilitant ainsi l'interprétation des segments de clients.\n",
    "\n",
    "1. **Instructions** : Utilisez les deux premières composantes principales obtenues avec la PCA pour visualiser les clusters K-means et les clusters hiérarchiques dans un espace 2D.\n",
    "\n",
    "2. **Indications** :\n",
    "   - **Visualisation des clusters K-means** :\n",
    "     - Créez un **nuage de points** en utilisant les deux composantes principales comme axes (`PCA Component 1` et `PCA Component 2`).\n",
    "     - Utilisez différentes couleurs pour chaque cluster de K-means.\n",
    "   - **Visualisation des clusters hiérarchiques** :\n",
    "     - Créez un second graphique en utilisant les mêmes composantes principales pour visualiser les clusters obtenus par le clustering hiérarchique.\n",
    "     - Ajoutez des légendes ou des étiquettes pour distinguer les clusters dans chaque graphique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "df5be028-0cd4-4cfe-97d6-7a2a1425eec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insérez ici le code pour visualiser les clusters K-means et hiérarchiques en 2D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21660836-b81f-4acf-bf07-415856386019",
   "metadata": {},
   "source": [
    "> **Question** : Les clusters apparaissent-ils bien séparés dans cet espace 2D ? Comment cette visualisation compare-t-elle aux résultats obtenus avant réduction de dimension ?\n",
    "\n",
    "> **Note** : Cette visualisation en 2D est un complément utile aux visualisations faites directement avec les variables originales dans K-means et le clustering hiérarchique. Elle permet de voir si les clusters sont bien séparés dans un espace réduit et si les patterns observés précédemment sont maintenus. Cette approche aide à **valider la cohérence des regroupements** et à mieux interpréter les segments de clients d’un point de vue global."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d9af0d-29c8-4fea-a151-a52371ecaf57",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "---\n",
    "## Challenges de l'Apprentissage Non Supervisé : Clustering et Réduction de Dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddeabe76-ef48-408c-99e5-bc6d30334d47",
   "metadata": {
    "tags": []
   },
   "source": [
    "Dans l’apprentissage non supervisé, en particulier pour le clustering et la réduction de dimension, plusieurs défis rendent l’interprétation et la validation des résultats complexes. Identifier ces limitations permet de mieux comprendre les résultats obtenus et de choisir les approches les plus adaptées pour des applications futures.\n",
    "\n",
    "### 1. Challenges du Clustering\n",
    "\n",
    "#### a) Absence de Guidance (Labels) pour Évaluer les Résultats\n",
    "   - **Description** : Contrairement à l’apprentissage supervisé, l’apprentissage non supervisé manque de labels ou de \"vérité terrain\" pour comparer les résultats. Il est donc difficile de savoir si les segments trouvés sont pertinents ou si l’on progresse dans la bonne direction.\n",
    "   - **Solutions** : Utiliser des métriques d’évaluation comme le **coefficient de silhouette** et des méthodes de visualisation (ex., PCA) pour obtenir des insights supplémentaires sur la qualité des clusters. Des feedbacks métier, si disponibles, peuvent aussi apporter des indications.\n",
    "\n",
    "#### b) Détermination du Nombre Optimal de Clusters\n",
    "   - **Description** : Déterminer le nombre optimal de clusters n’est pas évident, surtout lorsque les données ne présentent pas de séparation nette.\n",
    "   - **Solutions** : Des méthodes comme l’**Elbow Method** et le **coefficient de silhouette** peuvent fournir des points de repère pour estimer un nombre raisonnable de clusters. La visualisation en 2D après réduction de dimension peut aussi aider à affiner le choix.\n",
    "\n",
    "#### c) Sensibilité aux Valeurs Extrêmes et au Bruit\n",
    "   - **Description** : Des valeurs aberrantes peuvent influencer les résultats, surtout pour des algorithmes comme K-means, où les points extrêmes peuvent tirer les centroïdes.\n",
    "   - **Solutions** : Le prétraitement des données, comme la détection et le traitement des valeurs extrêmes, peut atténuer cet effet. Le clustering hiérarchique avec des critères de lien, comme le lien complet, peut également être moins sensible au bruit.\n",
    "\n",
    "#### d) Sensibilité à la Standardisation\n",
    "   - **Description** : Les performances des algorithmes de clustering dépendent souvent de la standardisation, particulièrement avec des mesures de distance comme la distance euclidienne.\n",
    "   - **Solutions** : Assurer que les données sont bien standardisées pour garantir que chaque variable contribue équitablement au clustering, surtout si les échelles varient.\n",
    "\n",
    "#### e) Interprétabilité des Clusters\n",
    "   - **Description** : Interpréter les clusters peut être difficile, surtout si les groupes ne forment pas de séparation nette ou manquent de sens métier.\n",
    "   - **Solutions** : Examiner les moyennes des variables dans chaque cluster et comparer les résultats de différentes méthodes de clustering pour identifier des segments interprétables. Les visualisations comme la PCA aident également à mieux comprendre les regroupements.\n",
    "\n",
    "#### f) Visualisation des Clusters en Hautes Dimensions\n",
    "   - **Description** : Visualiser des données en hautes dimensions est difficile et limite notre capacité à évaluer intuitivement les regroupements, ce qui complique l'interprétation des résultats.\n",
    "   - **Solutions** : Utiliser des techniques de réduction de dimension, comme la PCA, pour projeter les données dans un espace 2D ou 3D. Bien que cela implique une perte d’information, cela permet d’observer les clusters de manière plus intuitive.\n",
    "\n",
    "\n",
    "### 2. Challenges de la Réduction de Dimension\n",
    "\n",
    "#### a) Perte d’Information\n",
    "   - **Description** : La réduction de dimension entraîne souvent une perte d’information. Si la variance expliquée par les premières composantes est faible, cela peut nuire à la représentation des données.\n",
    "   - **Solutions** : Vérifier la proportion de variance expliquée par les composantes retenues. Si elle est insuffisante, il peut être nécessaire de conserver plus de dimensions ou d’envisager une autre méthode de réduction.\n",
    "\n",
    "#### b) Limitation aux Données Numériques\n",
    "   - **Description** : La PCA est limitée aux données numériques. L’application directe sur des données catégorielles n’est pas possible sans transformation.\n",
    "   - **Solutions** : Pour les données catégorielles, des techniques comme l’**Analyse des Correspondances Multiples (ACM)** ou des transformations numériques (ex., embeddings) sont mieux adaptées.\n",
    "\n",
    "#### c) Interprétabilité des Composantes\n",
    "   - **Description** : Les composantes principales sont des combinaisons linéaires des variables d’origine, ce qui les rend parfois difficiles à interpréter.\n",
    "   - **Solutions** : Analyser les contributions de chaque variable à chaque composante principale pour comprendre les axes, et ne pas se limiter à 2 dimensions si cela affecte l’interprétation.\n",
    "\n",
    "#### d) Risque de Simplification Excessive\n",
    "   - **Description** : En réduisant les dimensions, on peut perdre des détails importants ou des patterns cachés, surtout si les clusters sont complexes.\n",
    "   - **Solutions** : Utiliser la réduction de dimension principalement pour la visualisation, tout en conservant l’analyse complète des données dans leur espace d’origine pour l’interprétation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42d2354-d8bc-4ab1-bbe5-e6885b5adc4e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "---\n",
    "## Conclusion "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5f33d3-c56b-4d2b-ab1e-dfcc5f484383",
   "metadata": {},
   "source": [
    "Au cours de cette séance, nous avons exploré les bases de l'apprentissage non supervisé, avec un focus sur les techniques de **clustering** et de **réduction de dimension**. Nous avons appliqué deux méthodes de clustering, **K-means** et le **clustering hiérarchique**, pour segmenter un dataset client en groupes ayant des caractéristiques similaires. Chaque méthode de clustering nous a permis d'explorer différents regroupements, tout en mettant en lumière les forces et limites de chaque approche.\n",
    "\n",
    "La **réduction de dimension avec la PCA** a été utilisée pour visualiser les clusters dans un espace 2D, rendant la structure des groupes plus intuitive et permettant de comparer les clusters de K-means et du clustering hiérarchique. Cette visualisation nous a aidés à confirmer les regroupements observés et à affiner notre interprétation des segments.\n",
    "\n",
    "Enfin, nous avons discuté des **challenges** de l'apprentissage non supervisé, tels que le choix du nombre de clusters, l'absence de labels pour valider les résultats, et la complexité d'interprétation des composantes dans la réduction de dimension. Ces défis rappellent l'importance de bien préparer les données, de tester plusieurs approches, et d’utiliser des outils de visualisation et d’évaluation adaptés.\n",
    "\n",
    "En conclusion, cette séance nous a permis de comprendre comment exploiter les techniques de clustering et de réduction de dimension pour analyser et segmenter des données de manière autonome, en obtenant des insights précieux sans supervision directe.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
