{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1BiYrLdsEA8x2GpXzK-WYlNBIpLUvPIg4","timestamp":1729858501664},{"file_id":"1mBGQu2Y86v8P0FBI_2_fc9_jeOEs4OMd","timestamp":1729484619632}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["\n","\n","---\n","\n","\n","# **Introduction au Machine Learning avec Scikit-learn**\n","## **Partie II : Mod√®les simples de classification**\n","\n","\n","---\n","\n","Pour cette seconde partie d'introduction au module `scikit-learn`, nous allons nous int√©resser au deuxi√®me type de probl√®me en Machine Learning : le probl√®me de **classification**.\n","\n","L'objectif de cette introduction est :\n","\n","- D'introduire le probl√®me de classification.\n","- D'apprendre √† utiliser le module `scikit-learn` pour construire un mod√®le de classification, aussi appel√© ¬´classifieur¬ª.\n","- D'introduire des m√©triques utiles √† l'√©valuation des performances du mod√®le.\n","\n","## **Introduction √† la classification**\n","### **Objectif de la classification**\n","\n","En Apprentissage supervis√©, l'objectif est de pr√©dire la valeur d'une variable cible √† partir de variables explicatives.\n","\n","- Dans un probl√®me de **r√©gression**, la variable cible prend des **valeurs continues**. Ces valeurs sont num√©riques : prix d'une maison, quantit√© d'oxyg√®ne dans l'air d'une ville, etc...\n","La variable cible peut donc prendre une **infinit√© de valeurs.**\n","\n","- Dans un probl√®me de **classification**, la variable cible prend des **valeurs discr√®tes**. Ces valeurs peuvent √™tre num√©riques ou litt√©rales mais dans les deux cas, la variable cible prend un **nombre fini de valeurs**.\n","Les diff√©rentes valeurs prises par la variable cible sont ce qu'on appelle des **classes**.\n","\n","**L'objectif de la classification consiste donc √† pr√©dire la classe d'une observation √† partir de ses variables explicatives.**\n","\n","### **Un exemple de classification**\n","Prenons un exemple de classification **binaire**, autrement dit o√π il y a **deux** classes.\n","Nous cherchons √† d√©terminer si l'eau d'un ruisseau est potable ou non en fonction de sa concentration en substances toxiques et de sa teneur en sels min√©raux.\n","\n","Les deux classes sont donc **'potable'** et **'non potable'**.\n","\n","![sklearn_intro_classification_binaire](https://github.com/diaBabPro/colabs/blob/main/sklearn_intro_classification_binaire.png?raw=true)\n","\n","Sur la figure ci-dessus, chaque point repr√©sente un ruisseau dont la position sur le plan est d√©finie par ses valeurs de concentration en substances toxiques et de teneur en sels min√©raux.\n","\n","L'objectif sera de construire un **mod√®le capable d'attribuer une des deux classes** ('potable'/'non potable') √† un ruisseau dont on ne connait que ces deux variables.\n","\n","La figure ci-dessus sugg√®re l'existence de deux zones permettant de classifier les ruisseaux facilement :\n","\n","- Une zone o√π les ruisseaux sont potables (en haut √† gauche).\n","- Une zone o√π les ruisseaux sont non potables (en bas √† droite).\n","\n","Nous aimerions cr√©er un mod√®le capable de **s√©parer le jeu de donn√©es en deux parties** correspondant √† ces zones.\n","\n","Une technique simple serait de s√©parer les deux zones √† **l'aide d'une ligne**.\n","\n","- **(a)** Ex√©cuter la cellule suivante pour afficher la figure interactive.\n","\n","> - Les points **oranges** sont les ruisseaux **potables** et les points **bleus** sont les ruisseaux **non-potables**.\n","> - La **fl√®che rouge** correspond √† un **vecteur** d√©fini par  $ùë§=(ùë§1,ùë§2)$\n"," . La ligne rouge correspond au plan orthogonal (i.e. perpendiculaire) √†  ùë§\n"," . Vous pouvez modifier les coordonn√©es du vecteur  ùë§\n","  de deux fa√ßons :\n","    - En faisant d√©filer les curseurs `w_1` et `w_2`.\n","    - En cliquant sur les valeurs √† droite des curseurs puis en ins√©rant directement la valeur souhait√©e.\n","\n","- **(b)** Essayer de trouver un vecteur  ùë§\n","  tel que **le plan orthogonal √†  ùë§\n","  s√©pare parfaitement les deux classes de ruisseau**.\n","- **(c)** Une solution possible est donn√©e par le vecteur  $ùë§=(‚àí1.47,0.84)$\n"," . Est-ce que le vecteur  $ùë§=(1.47,‚àí0.84)$\n","  donne aussi une solution ?"],"metadata":{"id":"ZYQCKbs1Y6oK"}},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from ipywidgets import interact, FloatSlider\n","\n","def linear_classification():\n","    np.random.seed(42)\n","    n_points = 100\n","\n","    X_potable = np.random.multivariate_normal([-1, 1], [[0.2, 0], [0, 0.2]], n_points)\n","\n","    X_non_potable = np.random.multivariate_normal([1, -1], [[0.2, 0], [0, 0.2]], n_points)\n","\n","    X = np.vstack([X_potable, X_non_potable])\n","    y = np.hstack([np.ones(n_points), -1 * np.ones(n_points)])\n","\n","    def plot_classification(w1, w2):\n","        plt.figure(figsize=(8, 6))\n","\n","        plt.scatter(X_potable[:, 0], X_potable[:, 1], color='orange', label='Potable')\n","        plt.scatter(X_non_potable[:, 0], X_non_potable[:, 1], color='blue', label='Non-potable')\n","\n","        w = np.array([w1, w2])\n","        slope = -w[0] / w[1]\n","        intercept = 0\n","\n","        x_vals = np.linspace(-3, 3, 100)\n","        y_vals = slope * x_vals + intercept\n","        plt.plot(x_vals, y_vals, 'r', label=f'S√©paration: w=({w1:.2f}, {w2:.2f})')\n","\n","        plt.quiver(0, 0, w[0], w[1], angles='xy', scale_units='xy', scale=1, color='red')\n","\n","        plt.xlim(-3, 3)\n","        plt.ylim(-3, 3)\n","        plt.axhline(0, color='black',linewidth=0.5)\n","        plt.axvline(0, color='black',linewidth=0.5)\n","        plt.xlabel('Feature 1')\n","        plt.ylabel('Feature 2')\n","        plt.legend(loc='upper right')\n","        plt.title('Classification des ruisseaux')\n","        plt.grid(True)\n","        plt.show()\n","\n","    interact(plot_classification, w1=FloatSlider(min=-3, max=3, step=0.01, value=-1.47), w2=FloatSlider(min=-3, max=3, step=0.01, value=0.84))\n","\n","linear_classification()"],"metadata":{"id":"fn1RGNbxSoy0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["La classification que nous venons de faire est de type lin√©aire, c'est-√†-dire que nous avons utilis√© un plan lin√©aire pour s√©parer nos classes.\n","\n","Ainsi, l'objectif des mod√®les de classification lin√©aires est de trouver le vecteur  ùë§\n","  permettant de s√©parer au mieux les diff√©rentes classes.\n","Chaque mod√®le de type lin√©aire dispose de sa propre technique pour trouver ce vecteur.\n","\n","Il existe aussi des mod√®les de classification non-lin√©aires, que nous verrons plus tard.\n","\n","![sklearn_intro_classification_lin_non_lin](https://github.com/diaBabPro/colabs/blob/main/sklearn_intro_classification_lin_non_lin.png?raw=true)\n","\n","\n","## **1.   Utilisation de `scikit-learn` pour la classification**\n","\n","\n","Nous allons maintenant introduire les principaux outils du module `scikit-learn` essentiels √† la r√©solution d'un probl√®me de classification.\n","\n","Dans cet exercice, nous utiliserons le jeu de donn√©es [Congressional Voting Records](https://archive.ics.uci.edu/ml/datasets/congressional+voting+records) qui contient un nombre de votes faits par les membres du Congr√®s de la Chambre des Repr√©sentants des √âtats-Unis.\n","\n","L'objectif de notre probl√®me de classification sera de **pr√©dire le parti politique** (\"d√©mocrate\" ou \"r√©publicain\") des membres de la Chambre des Repr√©sentants en fonction de leurs votes sur des sujets comme l'√©ducation, la sant√©, le budget, etc...\n","\n","Les variables explicatives seront donc les votes sur diff√©rents sujets et la variable cible sera le parti politique \"d√©mocrate\" ou \"r√©publicain\".\n","\n","Pour r√©soudre ce probl√®me nous allons utiliser un mod√®le de classification lin√©aire : la **R√©gression Logistique**.\n","\n","### **Pr√©paration des donn√©es**\n","- **(a)** Ex√©cuter la cellule suivante pour importer les modules `pandas` et `numpy` n√©cessaires √† la suite de l'exercice."],"metadata":{"id":"-dZKYyPje82V"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","%matplotlib inline"],"metadata":{"id":"KNgi1Ya2fgp3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- **(b)** Charger les donn√©es contenues dans le fichier `'votes.csv'` dans un `DataFrame` nomm√© votes."],"metadata":{"id":"t4unkFnLfiWY"}},{"cell_type":"code","source":["# Ins√©rez votre code ici"],"metadata":{"id":"DHcswJr3fo--"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Afin de visualiser bri√®vement nos donn√©es :\n","\n","- **(c)** Afficher le nombre de lignes et de colonnes de `votes`.\n","- **(d)** Afficher un aper√ßu des 20 premi√®res lignes de `votes`."],"metadata":{"id":"TvKM-GBnfsD9"}},{"cell_type":"code","source":["# Ins√©rez votre code ici"],"metadata":{"id":"DQEZ2CmKfylL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- La premi√®re colonne **`\"party\"`** contient le nom du **parti politique** auquel chaque membre du Congr√®s de la Chambre des Repr√©sentants appartient.\n","- Les **16 colonnes** suivantes contiennent les votes de chaque membre du Congr√®s sur des propositions de lois :\n","  - `'y'` indique que l'√©lu a vot√© **pour** la proposition de loi.\n","  - `'n'` indique que l'√©lu a vot√© **contre** la proposition de loi.\n","Afin d'utiliser les donn√©es dans un mod√®le de classification, il est n√©cessaire de transformer ces colonnes en valeurs **num√©riques** binaires, autrement dit soit 0 soit 1.\n","\n","- **(e)** Pour chacune des colonnes 1 √† 16 (la colonne 0 √©tant notre variable cible), remplacer les valeurs `'y'` par 1 et `'n'` par 0. Pour cela, on peut s'aider de la m√©thode **`replace`** de la classe `DataFrame`.\n","- **(f)** Afficher les 10 premi√®res lignes du `DataFrame` modifi√©."],"metadata":{"id":"5DbgE9k7f2aT"}},{"cell_type":"code","source":["# Ins√©rez votre code ici"],"metadata":{"id":"PKWos1j8gMzl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- **(g)** Dans un `DataFrame` nomm√© `X`, stocker les variables **explicatives** du jeu de donn√©es (toutes les colonnes sauf `'party'`). Pour cela, vous pourrez vous aider de la m√©thode **`drop`** d'un `DataFrame`.\n","- **(h)** Dans une `Series` nomm√© `y`, stocker la **variable cible** (`'party'`)."],"metadata":{"id":"3WUoxo7FgRUY"}},{"cell_type":"code","source":["# Ins√©rez votre code ici"],"metadata":{"id":"MAtpuMXhgeIH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Comme pour la r√©gression, nous allons devoir s√©parer le jeu de donn√©es en 2 parties : un jeu **d'entra√Ænement** et un jeu de **test**. Pour rappel :\n","\n",">- Le jeu d'entra√Ænement sert √† **entra√Æner le mod√®le** de classification, c'est-√†-dire trouver les param√®tres du mod√®le qui s√©parent au mieux les classes.\n",">- Le jeu de test sert √† **√©valuer** le mod√®le sur des donn√©es qu'il n'a jamais vues. Cette √©valuation nous permettra de juger sur la capacit√© √† **g√©n√©raliser** du mod√®le.\n","\n","- **(i)** Importer la fonction `train_test_split` du sous module `sklearn.model_selection`. On rappelle que cette fonction s'utilise ainsi :\n","\n","```python\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n","```\n","\n","- **(j)** S√©parer les donn√©es en un jeu d'entra√Ænement `(X_train, y_train)` et un jeu de test `(X_test, y_test)` en gardant 20% des donn√©es pour l'√©chantillon de test.\n","\n",">Pour √©liminer l'al√©a de la fonction `train_test_split`, vous pouvez utiliser le param√®tre `random_state` avec une valeur enti√®re (par exemple random_state = 2).\n","Ainsi, √† chaque fois que vous utiliserez la fonction avec l'argument `random_state = 2`, les jeux de donn√©es produits seront les m√™mes."],"metadata":{"id":"PWp8vN3PghpU"}},{"cell_type":"code","source":["# Ins√©rez votre code ici"],"metadata":{"id":"i0cUKEOvgmmR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Le mod√®le de r√©gression logistique est √©troitement li√© au mod√®le de **r√©gression lin√©aire** vu dans le pr√©c√©dent notebook.\n","\n","Il ne faut pas les **confondre** puisqu'ils ne r√©solvent pas les m√™mes types de probl√®mes :\n","\n","La r√©gression **logistique** est utilis√©e pour la classification (pr√©dire des classes).\n","La r√©gression **lin√©aire** est utilis√©e pour la r√©gression (pr√©dire une variable quantitative).\n","Le mod√®le de r√©gression lin√©aire √©tait d√©fini par la formule suivante :\n","$ùë¶‚âàŒ≤0+\\sum_{j=1}^{p} Œ≤ùëóùë•ùëó$\n","\n","La r√©gression logistique n'estime plus  ùë¶\n","  directement mais la **probabilit√©** que  ùë¶\n","  soit √©gal √† 0 ou 1.\n","Ainsi, le mod√®le est d√©fini par la formule :\n","\n","$ùëÉ(ùë¶=1)=ùëì(ùõΩ0+\\sum_{j=1}^{p}ùõΩùëóùë•ùëó)$\n","\n","O√π\n","\n","$f(x) = \\frac{1}{1 + e^{-x}}$\n","\n","\n","La fonction  ùëì\n"," , souvent appel√©e **sigmo√Øde** ou **fonction logistique**, permet de transformer la combinaison lin√©aire  $ùë¶‚âàŒ≤0+\\sum_{j=1}^{p} Œ≤ùëóùë•ùëó$\n","  en une valeur comprise entre 0 et 1 que l'on pourra interpr√©ter comme une **probabilit√©** :\n","\n","- Si  $ùë¶‚âàŒ≤0+\\sum_{j=1}^{p} Œ≤ùëóùë•ùëó$\n","  est positif, alors  $ùëÉ(ùë¶=1)>0.5$\n"," , donc la classe pr√©dite de l'observation sera 1.\n","\n","- Si  $ùë¶‚âàŒ≤0+\\sum_{j=1}^{p} Œ≤ùëóùë•ùëó$\n","  est n√©gatif, alors  $ùëÉ(ùë¶=1)<0.5$\n"," , c'est-√†-dire que  $ùëÉ(ùë¶=0)>0.5$\n"," , donc la classe pr√©dite de l'observation sera 0.\n","\n","- **(k)** Importer la classe `LogisticRegression` du sous-module `linear_model` de `scikit-learn`.\n","- **(l)** Instancier un mod√®le `LogisticRegression` nomm√© **`logreg`** sans pr√©ciser d'arguments du constructeur.\n","- **(m)** Entra√Æner le mod√®le sur le jeu de donn√©es d'entra√Ænement gr√¢ce √† la m√©thode `fit` de la classe `LogisticRegression`.\n","- **(n)** Effectuer une pr√©diction sur les donn√©es de **test**. Stocker ces pr√©dictions dans **`y_pred_test_logreg`** et afficher les 10 premi√®res pr√©dictions."],"metadata":{"id":"rtmipQCxhFui"}},{"cell_type":"code","source":["# Ins√©rez votre code ici"],"metadata":{"id":"cEvw7proiRok"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **2. Evaluer la performance d'un mod√®le de classification**\n","\n","Il existe diff√©rentes m√©triques pour √©valuer les performances de mod√®les de classification comme :\n","\n","- L'**accuracy**.\n","- La **pr√©cision et le rappel** (precision et *recall* en anglais).\n","\n","Chaque m√©trique √©value la performance du mod√®le avec une approche diff√©rente.\n","\n","Afin d'expliquer ces notions, nous allons introduire 4 termes tr√®s importants.\n","\n","**Arbitrairement**, nous allons choisir que la classe **'republican' sera la classe positive** (1) et **'democrat' sera la classe n√©gative** (0).\n","\n","Ainsi, nous appellerons :\n","\n","- **Vrai positif (VP)** une observation class√©e **positive** ('republican') par le mod√®le et qui est effectivement **positive** ('republican').\n","- **Faux positif (FP)** une observation class√©e **positive** ('republican') par le mod√®le mais qui √©tait en r√©alit√© **n√©gative** ('democrat').\n","- **Vrai n√©gatif (VN)** une observation class√©e **n√©gative** ('democrat') par le mod√®le et qui est effectivement **n√©gative** ('democrat').\n","- **Faux n√©gatif (FN)** une observation class√©e **n√©gative** ('democrat') par le mod√®le mais qui √©tait en r√©alit√© **positive** ('republican').\n","\n","![sklearn_intro_positif_negatif](https://github.com/diaBabPro/colabs/blob/main/sklearn_intro_positif_negatif.png?raw=true)\n","\n","L'**accuracy** est la m√©trique la plus couramment utilis√©e pour √©valuer un mod√®le.\n","Elle correspond simplement au taux de pr√©dictions **correctes** effectu√©es par le mod√®le.\n","\n","On suppose que l'on dispose de  ùëõ\n","  observations.\n","On note  VP\n","  le nombre de Vrais Positifs et  VN\n","  le nombre de Vrais N√©gatifs.\n","L'accuracy est alors donn√©e par :\n","\n","$accuracy=\\frac{VP+VN}{ùëõ}$\n","\n","La **pr√©cision** est une m√©trique qui r√©pond √† la question : **Parmi toutes les pr√©dictions positives du mod√®le, combien sont de vrais positifs ?**\n","\n","Si on note  FP\n","  le nombre de Faux Positifs du mod√®le, alors la pr√©cision est donn√©e par :\n","\n","$precision=\\frac{VP}{VP+FP}$\n","\n","Un score de pr√©cision √©lev√© nous informe que le mod√®le ne classe pas aveugl√©ment toutes les observations comme positives.\n","\n","Le **rappel** est une m√©trique qui quantifie la proportion d'observations r√©ellement positives qui ont √©t√© correctement classifi√©es positives par le mod√®le.\n","\n","Si on note  FN\n","  le nombre de Faux N√©gatifs, alors le rappel est donn√© par :\n","\n","$rappel=\\frac{VP}{VP+FN}$\n","\n","Un score de rappel √©lev√© nous informe que le mod√®le est capable de bien d√©tecter les observations r√©ellement positives.\n","\n","La **matrice de confusion** compte pour un jeu de donn√©es les valeurs de VP, VN, FP et FN, ce qui nous permet de calculer les trois m√©triques pr√©c√©dentes :\n","\n","$\\text{Confusion Matrix} =\n","\\begin{pmatrix}\n","\\text{VN} & \\text{FP} \\\\\n","\\text{FN} & \\text{VP}\n","\\end{pmatrix}$\n","\n","La fonction **`confusion_matrix`** du sous-module `sklearn.metrics` permet de g√©n√©rer la matrice de confusion √† partir des pr√©dictions d'un mod√®le :\n","\n","```python\n","confusion_matrix(y_true, y_pred)\n","```\n","\n",">- **`y_true`** contient les **vraies** valeurs de y.\n",">- **`y_pred`** contient les valeurs **pr√©dites** par le mod√®le.\n","\n","L'affichage de la matrice de confusion peut se faire aussi avec la fonction **pd.crosstab** :\n","\n","- **(a)** Importer les fonctions **`accuracy_score`**, **`precision_score`** et **`recall_score`** du sous-module `sklearn.metrics`.\n","- **(b)** Afficher la matrice de confusion des pr√©dictions du mod√®le **`logreg`** √† l'aide de **`pd.crosstab`**.\n","- **(c)** Calculer l'accuracy, la pr√©cision et le rappel des pr√©dictions du mod√®le **`logreg`**. Pour utiliser les m√©triques `precision_score` et `recall_score`, il faudra renseigner l'argument **`pos_label = 'republican'`** afin de pr√©ciser que la classe `'republican'` est la classe positive."],"metadata":{"id":"FDSk3KHiiVOQ"}},{"cell_type":"code","source":["# Ins√©rez votre code ici"],"metadata":{"id":"ITl3BM1vifKz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Recap**\n","Scikit-learn propose de nombreux mod√®les de classification comme **`LogisticRegression`**.\n","\n","L'utilisation de ces mod√®les se fait de la m√™me fa√ßon pour **tous** les mod√®les de scikit-learn :\n","\n","- **Instanciation** du mod√®le.\n","- **Entra√Ænement** du mod√®le : **`model.fit(X_train, y_train)`**.\n","- **Pr√©diction** : **`model.predict(X_test)`**.\n","\n","La pr√©diction sur le jeu de test nous permet d'**√©valuer** la performance du mod√®le gr√¢ce √† des **m√©triques** adapt√©es.\n","\n","Les m√©triques que nous avons vues s'utilisent pour la classification **binaire** et se calculent gr√¢ce √† 4 valeurs :\n","\n","- Vrais Positifs : Pr√©diction = + | R√©alit√© = +\n","- Vrais N√©gatifs : Pr√©diction = - | R√©alit√© = -\n","- Faux Positifs : Pr√©diction = + | R√©alit√© = -\n","- Faux N√©gatifs : Pr√©diction = - | R√©alit√© = +\n","\n","Toutes ces valeurs peuvent se calculer √† l'aide de la **matrice de confusion** g√©n√©r√©e par la fonction **`confusion_matrix`** du sous-module `sklearn.metrics` ou par la fonction **`pd.crosstab`**.\n","\n","Gr√¢ce √† ces valeurs, nous pouvons calculer des m√©triques comme :\n","\n","- L'**accuracy** : La proportion d'observations correctement classifi√©es.\n","- La **pr√©cision** : La proportion de vrais positifs parmi toutes les pr√©dictions positives du mod√®le.\n","- Le **rappel** : La proportion d'observations r√©ellement positives qui ont √©t√© correctement classifi√©es positives par le mod√®le.\n","\n","Toutes ces m√©triques peuvent s'obtenir √† l'aide de la fonction **`classification_report`** du sous-module **`sklearn.metrics`**."],"metadata":{"id":"UUc6bUPYik2a"}}]}